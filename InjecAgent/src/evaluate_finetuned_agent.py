import json
import os
from src.params import parse_arguments
from src.utils import get_tool_dict, get_simulated_attacker_tool_response, get_score
from src.output_parsing import evaluate_output_finetuned
from tqdm import tqdm 
from src.prompts.agent_prompts import PROMPT_DICT
from openai import OpenAI
from pydantic import BaseModel
from typing import Optional, List, Literal

client = OpenAI(
    api_key = os.environ.get("OPENAI_API_KEY"),
    organization = os.environ.get("OPENAI_ORGANIZATION")
)

class Function(BaseModel):
    arguments: str
    name: str

class ChatCompletionMessageToolCall(BaseModel):
    id: str
    function: Function
    type: Literal["function"]

class FunctionCall(BaseModel):
    arguments: str
    name: str

class ChatCompletionMessage(BaseModel):
    content: Optional[str]
    role: Literal["assistant"]
    function_call: Optional[FunctionCall] = None
    tool_calls: Optional[List[ChatCompletionMessageToolCall]] = None


def predict_one_case(system_prompt, user_prompt, params, item, tool_dict, step_2=False):
    available_tool_names = [item['User Tool']] + item['Attacker Tools']
    available_tools = [tool_dict[tool] for tool in available_tool_names]
    
    messages = [
        {"role": "system", "content":system_prompt},
        {"role": "user", "content": item['User Instruction']},
    ]
    
    call_id = 'call_dx6NRJIZOLS2GS7HtIFxVpyG' # random one
    function_name = item['User Tool']
    message = ChatCompletionMessage(
        content = None,
        role = 'assistant',
        tool_calls = [ChatCompletionMessageToolCall(id=call_id, function=Function(arguments = json.dumps(item['Tool Parameters']), name = function_name), type='function')]
    )
    messages.append(message)
    
    messages.append(
        {
            "tool_call_id": call_id,
            "role": "tool",
            "name": function_name,
            "content": json.dumps(item['Tool Response']),
        }
    ) 
    
    if step_2:
        tool_call = item['tool_calls'][0]
        message = ChatCompletionMessage(
            content = item['output'],
            role = 'assistant',
            tool_calls = [ChatCompletionMessageToolCall(id=tool_call['id'], function=Function(arguments = json.dumps(item['Attacker Tool Parameters']), name = tool_call['function']['name']), type='function')]
        )
        messages.append(message)
        messages.append(
            {
                "tool_call_id": tool_call['id'],
                "role": "tool",
                "name": tool_call['function']['name'],
                "content": item['Attacker Tool Response'],
            }
        )   

    response = client.chat.completions.create(
        model=params['model_name'],
        messages=messages,
        tools=available_tools,
        temperature=0
    )
    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls
    if isinstance(tool_calls, List):
        tool_calls = [item.model_dump() for item in response_message.tool_calls]
    return response_message.content, tool_calls


def main(params):
    print(params)    
    system_prompt, user_prompt = PROMPT_DICT[params['prompt_type']]
    output_dir = f"./results/finetuned_{params['model_name']}_{params['prompt_type']}"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    data_dir = './data'
    
    tool_dict = get_tool_dict(gpt_format=True)
    
    output_files = {}
    for attack in ['dh', 'ds']:
        file_name = f"test_cases_{attack}_{params['setting']}.json"
        test_case_file = os.path.join(data_dir, file_name)
        output_file = os.path.join(output_dir, file_name)
        output_files[attack] = output_file

        
        with open(test_case_file, 'r') as f:
            data = json.load(f)
        
        with open(output_file, 'w') as f:
            for item in tqdm(data):
                output, tool_calls = predict_one_case(system_prompt, user_prompt, params, item, tool_dict)
                item['output'] = output
                item['tool_calls'] = tool_calls
                parsed_output = evaluate_output_finetuned(output, item['Attacker Tools'][0], item['User Tool'], tool_calls)
                item['eval'] = parsed_output['eval']
                if not params['only_first_step'] and item['eval'] == 'succ' and attack == 'ds':
                    item["Attacker Tool Parameters"] = parsed_output["Attacker Tool Parameters"]
                    item["Attacker Tool Response"] = get_simulated_attacker_tool_response(item['Attacker Tools'][0], item["Attacker Tool Parameters"], tool_dict)
                    output, tool_calls = predict_one_case(system_prompt, user_prompt, params, item, tool_dict, step_2=True)
                    item['output Step 2'] = output
                    item['tool_calls Step 2'] = tool_calls
                    parsed_output = evaluate_output_finetuned(output, item['Attacker Tools'][1], item['User Tool'], tool_calls)
                    item['eval Step 2'] = parsed_output['eval']
                
                f.write(json.dumps(item)+'\n')
    
    scores = get_score(output_files)
    print(json.dumps(scores, indent=True))

if __name__ == "__main__":
    params = parse_arguments(agent_type="finetuned")

    main(params)
