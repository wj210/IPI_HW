{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8190c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append(os.path.abspath(\".\")) \n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from utils.utils import *\n",
    "from utils.plot_utils import *\n",
    "torch.set_grad_enabled(False)\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "seed_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7681da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "data_dir = '/dataset/common/huggingface/model'\n",
    "torch_dtype = torch.bfloat16\n",
    "max_ctx_len = 32768\n",
    "model_path = 'Qwen/Qwen3-8B'\n",
    "# model_path = os.path.join(data_dir,'Qwen3-8B-Toolace_ASIDE')\n",
    "# model,tokenizer,is_aside = load_model(model_path,use_vllm=True,dtype=torch_dtype,vllm_kwargs = {'gpu_memory_utilization':0.8,'enable_chunked_prefill':False},max_ctx_len=max_ctx_len)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea920b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = {}\n",
    "with open(\"/export/home2/weijie210/ToolBench/ToolBench_data/data/toolllama_G123_dfs_train.json\",\"r\") as f:\n",
    "    ds['train'] = json.load(f)\n",
    "\n",
    "with open(\"/export/home2/weijie210/ToolBench/ToolBench_data/data/toolllama_G123_dfs_eval.json\",\"r\") as f:\n",
    "    ds['eval'] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc1da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 149982 samples with tool use, 37560 samples without tool use\n",
      "eval: 609 samples with tool use, 153 samples without tool use\n"
     ]
    }
   ],
   "source": [
    "tool_ds = {}\n",
    "non_tool_ds = {}\n",
    "for ds_key, ds_ in ds.items():\n",
    "    tool_ds[ds_key] = [d for d in ds_ if any([t['from'] == 'function' for t in d['conversations']])]\n",
    "    non_tool_ds[ds_key] = [d for d in ds_ if not any([t['from'] == 'function' for t in d['conversations']])]\n",
    "    print (f'{ds_key}: {len(tool_ds[ds_key])} samples with tool use, {len(non_tool_ds[ds_key])} samples without tool use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816a3bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast,copy\n",
    "\n",
    "def parse_assistant_response(response):\n",
    "    action_input = None\n",
    "    action = None\n",
    "    thought = None\n",
    "    if \"Action Input:\" in response:\n",
    "        action_input = response.split(\"Action Input:\")[-1].strip().replace('\\n',' ')\n",
    "        try:\n",
    "            action_input = json.loads(action_input)\n",
    "        except:\n",
    "            try:\n",
    "                action_input = ast.literal_eval(action_input)\n",
    "            except:\n",
    "                action_input = None\n",
    "        if action_input is not None:\n",
    "            if \"Action:\" in response:\n",
    "                action = response.split(\"Action:\")[-1].split(\"Action Input:\")[0].strip()\n",
    "                thought = response.split(\"Thought:\")[-1].split(\"Action:\")[0].strip()\n",
    "    elif \"Action:\" in response:\n",
    "        action = response.split(\"Action:\")[-1].strip()\n",
    "        thought = response.split(\"Thought:\")[-1].split(\"Action:\")[0].strip()\n",
    "    return thought, action, action_input\n",
    "\n",
    "def convert_turn_keys(messages):\n",
    "    messages = copy.deepcopy(messages)\n",
    "    for m in messages:\n",
    "        m['role'] = m.pop('from')\n",
    "        m['content'] = m.pop('value')\n",
    "        if m['role'] == 'function':\n",
    "            m['role'] = 'tool'\n",
    "    return messages\n",
    "\n",
    "def format_assistant_response(action,action_input):\n",
    "    out_format = \"<tool_call>\\n{tool_call}\\n</tool_call>\"\n",
    "    tool_call = json.dumps({\n",
    "        'name': action,\n",
    "        'arguments': action_input\n",
    "    })\n",
    "    return out_format.format(tool_call = tool_call)\n",
    "\n",
    "def process_tool_response(resp):\n",
    "    str_resp =  resp.replace('<tool_call>','').replace('</tool_call>','').strip()\n",
    "    try:\n",
    "        tool_call = json.loads(str_resp)\n",
    "    except:\n",
    "        try:\n",
    "            tool_call = ast.literal_eval(str_resp)\n",
    "        except:\n",
    "            tool_call = None\n",
    "    return tool_call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d96f81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 26436/149982 [00:13<00:50, 2455.00it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 20%|██        | 30508/149982 [00:14<00:48, 2485.54it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\$'\n",
      " 32%|███▏      | 48523/149982 [00:23<00:39, 2573.36it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      " 35%|███▌      | 52681/149982 [00:25<00:37, 2598.92it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 38%|███▊      | 56577/149982 [00:27<00:41, 2229.97it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      " 43%|████▎     | 64601/149982 [00:30<00:34, 2484.29it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 45%|████▍     | 67454/149982 [00:31<00:32, 2555.36it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 49%|████▉     | 73916/149982 [00:35<00:29, 2576.88it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 54%|█████▍    | 81631/149982 [00:38<00:27, 2478.43it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 57%|█████▋    | 85764/149982 [00:41<01:38, 651.65it/s] <unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 61%|██████    | 91713/149982 [00:44<00:22, 2544.81it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 61%|██████▏   | 92227/149982 [00:44<00:22, 2552.75it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 64%|██████▍   | 96652/149982 [00:46<00:20, 2626.56it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\.'\n",
      " 71%|███████   | 106248/149982 [00:51<00:31, 1378.64it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 76%|███████▌  | 113249/149982 [00:54<00:14, 2602.11it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\.'\n",
      " 76%|███████▌  | 113771/149982 [00:54<00:14, 2584.63it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      " 89%|████████▊ | 132793/149982 [01:03<00:06, 2511.32it/s]<unknown>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "100%|██████████| 149982/149982 [01:10<00:00, 2133.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 148007 samples for on-policy generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 609/609 [00:00<00:00, 2638.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: 600 samples for on-policy generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_tool_ds = defaultdict(list) # for tool use, randomly select one valid assistant turn with tool use\n",
    "for ds_key, ds_ in tool_ds.items():\n",
    "    for sample in tqdm(ds_,total = len(ds_)):\n",
    "        sample = copy.deepcopy(sample) \n",
    "        conversations = sample['conversations'] \n",
    "        valid_assistant_turns = []\n",
    "        start_tracking = False\n",
    "        for i,turn in enumerate(conversations):\n",
    "            if turn['from'] == 'system':\n",
    "                system_prompt = turn['value'] # get the tools\n",
    "                tools = system_prompt.split('you have access to the following APIs:')[-1].strip()\n",
    "                tools = ast.literal_eval(tools)\n",
    "                if not isinstance(tools, list) and not all([isinstance(t, dict) for t in tools]): # cant parse properly.\n",
    "                    break\n",
    "                tools = [t for t in tools if t['name'].lower() != 'finish']\n",
    "            if turn['from'] == 'function':\n",
    "                start_tracking = True\n",
    "            if turn['from'] == 'assistant':\n",
    "                thought, action, action_input = parse_assistant_response(turn['value'])\n",
    "                if thought is None or action is None or action_input is None: # cant parse assistant resp\n",
    "                    break\n",
    "                turn['value'] = format_assistant_response(action,action_input)\n",
    "                if action.lower().strip() =='finish': # not a tool, just the string\n",
    "                    if 'final_answer' not in action_input: # end of turn fail since no final answer\n",
    "                        break\n",
    "                    turn['value'] = action_input['final_answer']\n",
    "                if start_tracking:\n",
    "                    valid_assistant_turns.append(conversations[1:i+1])\n",
    "            # we select each assistant turn (if there exist a tool use before) as a valid training sample, \n",
    "            # Then random select one \n",
    "        if len(valid_assistant_turns): \n",
    "            random_to_generate_id = np.random.choice(range(len(valid_assistant_turns)))\n",
    "            random_to_generate = convert_turn_keys(valid_assistant_turns[random_to_generate_id])\n",
    "            filtered_tool_ds[ds_key].append({'conversations':random_to_generate,'tools':tools}) # remove the system prompt\n",
    "\n",
    "    print (f'{ds_key}: {len(filtered_tool_ds[ds_key])} samples for on-policy generation')\n",
    "\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5828ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_prompt_format(messages,tools,tokenizer,encode=False,enable_thinking=False): # for tool-use agents like Qwen\n",
    "    if messages[-1]['role'] == 'assistant':\n",
    "        add_generation_prompt = True\n",
    "    else:\n",
    "        add_generation_prompt = False\n",
    "    if 'qwen' in tokenizer.name_or_path.lower():\n",
    "        formatted = tokenizer.apply_chat_template(messages,add_generation_prompt=add_generation_prompt,tokenize=False,enable_thinking=enable_thinking,tools=tools)\n",
    "    else:\n",
    "        formatted = tokenizer.apply_chat_template(messages,add_generation_prompt=add_generation_prompt,tokenize=False,tools=tools)\n",
    "    return encode_fn(formatted,tokenizer) if encode else formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8084dfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid counts (tool ds):  {'train': 0, 'eval': 0}\n"
     ]
    }
   ],
   "source": [
    "def check_valid(sample):\n",
    "    conversations = sample['conversations']\n",
    "    turns = [t['role'] for t in conversations][2:]\n",
    "    ## check that there is at least one turn after each tool turn\n",
    "    for i,role in enumerate(turns):\n",
    "        if role == 'tool':\n",
    "            if i == len(turns) - 1 or turns[i+1] not in ['assistant','user']:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "invalid_count = {k: sum([check_valid(s) for s in v]) for k,v in filtered_tool_ds.items()}\n",
    "print (\"Invalid counts (tool ds): \", invalid_count) # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing input lengths:  18%|█▊        | 26622/148007 [00:33<02:33, 792.00it/s] \n"
     ]
    }
   ],
   "source": [
    "# filtered next by length\n",
    "MAX_LENGTH = 4096\n",
    "def compute_length(sample):\n",
    "    text = tool_prompt_format(\n",
    "        sample[\"conversations\"],\n",
    "        tools=sample[\"tools\"],\n",
    "        tokenizer=tokenizer,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "    length = len(tokenizer.encode(text, add_special_tokens=True))\n",
    "    sample[\"input_len\"] = length\n",
    "    return sample\n",
    "\n",
    "MAX_LENGTH = 4096 - 512\n",
    "filtered_tool_ds = {k:async_process(compute_length, filtered_tool_ds[k], workers=32, msg=\"Computing input lengths\") for k in filtered_tool_ds.keys()}\n",
    "    \n",
    "filtered_tool_ds = {k: [d for d in filtered_tool_ds[k] if d['input_len'] < MAX_LENGTH] for k in filtered_tool_ds.keys()}\n",
    "\n",
    "print (f'After filtering by length < {MAX_LENGTH}, we have {len(filtered_tool_ds[\"train\"])} train samples and {len(filtered_tool_ds[\"eval\"])} val samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "373ab283",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_ds = [{'conversations':d['input'],'tools':d['tools']} for d in filtered_train_ds]\n",
    "filtered_val_ds = [{'conversations':d['input'],'tools':d['tools']} for d in filtered_val_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44822457",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aside/data/train_data/toolbench_train_4096.json','w') as f:\n",
    "    json.dump(filtered_train_ds,f,indent=4)\n",
    "\n",
    "with open('aside/data/train_data/toolbench_val_4096.json','w') as f:\n",
    "    json.dump(filtered_val_ds,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6994d391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipi_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
