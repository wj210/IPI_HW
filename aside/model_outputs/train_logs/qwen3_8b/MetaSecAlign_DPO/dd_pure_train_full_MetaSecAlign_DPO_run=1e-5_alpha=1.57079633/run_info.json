{"desc": "Qwen3 8B base model trained with MetaSecAlign_DPO", "name": "dd_pure_MetaSecAlign_DPO", "checkpoint_path": "/dataset/common/huggingface/model/qwen3_8b_1e-5_MetaSecAlign_DPO", "instruct_model_path": "Qwen/Qwen3-8B", "data_model_path": "Qwen/Qwen3-8B", "chat_template_path": null, "parent_pure_model_name": "dd_pure", "run_number": "1e-5", "hyperparams": {"train_type": "full", "output_dir": "/dataset/common/huggingface/model", "num_train_epochs": 1.0, "per_device_train_batch_size": 8, "per_device_eval_batch_size": 8, "gradient_accumulation_steps": 2, "learning_rate": 1e-05, "weight_decay": 0.0, "max_length": 2048, "lr_scheduler_type": "cosine", "warmup_ratio": 0.1, "logging_dir": "./logs", "logging_steps": 10, "evaluation_strategy": "steps", "save_strategy": "steps", "eval_steps": 29, "eval_percent": 0.1, "save_steps": 29, "num_data": -1, "save_total_limit": 1, "load_best_model_at_end": true, "prediction_loss_only": true, "bf16": true, "activation_checkpointing": false, "remove_unused_columns": false, "report_to": "wandb", "embedding_init": "rot_isoclinic", "rotation_alpha": 1.57079633, "add_linear_shift": false, "learned_rotation": false, "gradual_rotation": false, "rotation_direction": "right", "local_rank": 0, "post_init_rotation": false, "gradual_rot": false, "no_deepspeed": false, "mode": "dpo", "beta": 0.1, "completion_only": false}}