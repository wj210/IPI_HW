{
    "desc": "Qwen rotating embedding, alpaca shuffled",
    "train_dataset_path": "/export/home2/weijie210/ipi_huawei/aside/data/train_data/toolbench_train_4096.json",
    "eval_dataset_path": "/export/home2/weijie210/ipi_huawei/aside/data/train_data/toolbench_val_4096.json",
    "eval_input_path": "n/a, set in code",
    "prompt_templates_path": "./data/prompt_templates.json",
    "output_base_path": "./model_outputs/",
    "train_logs_path": "./model_outputs/train_logs/",
    "training_version": "ToolBench-SFT",
    "tokenizer_path": "meta-llama/Llama-3.1-8B-Instruct",
    "assistant_token": ["<|start_header_id|>assistant<|end_header_id|>","<|eot_id|>"],
    "tool_token": ["<|start_header_id|>ipython<|end_header_id|>","<|eot_id|>"],
    "user_token": ["<|start_header_id|>user<|end_header_id|>","<|eot_id|>"],
    "models": {
        "single_emb": {
            "pure_models": [
                {
                    "name": "dd_pure",
                    "desc": "Llama3.1 8B base model",
                    "checkpoint_to_load_from": null,
                    "checkpoint_to_load_to": "./models/Llama3.1-8B/single",
                    "chat_template_path": null,
                    "instruct_model_path": "meta-llama/Llama-3.1-8B-Instruct",
                    "data_model_path": "meta-llama/Llama-3.1-8B-Instruct"
                }
            ]
        },
        "ise": {
            "pure_models": [
                {
                    "name": "ise",
                    "desc": "Llama3.1 8B base model",
                    "checkpoint_to_load_from": null,
                    "checkpoint_to_load_to": "./models/Llama3.1-8B/ise",
                    "chat_template_path": null,
                    "instruct_model_path": "meta-llama/Llama-3.1-8B-Instruct",
                    "data_model_path": "meta-llama/Llama-3.1-8B-Instruct"
                }
            ]
        },
        "forward_rot": {
            "pure_models": [
                {
                    "name": "forward_rot",
                    "desc": "Llama3.1 8B base model",
                    "checkpoint_to_load_from": null,
                    "checkpoint_to_load_to": "./models/Llama3.1-8B/forward_rot",
                    "chat_template_path": null,
                    "instruct_model_path": "meta-llama/Llama-3.1-8B-Instruct",
                    "data_model_path": "meta-llama/Llama-3.1-8B-Instruct"
                }
            ]
        }
    }
}