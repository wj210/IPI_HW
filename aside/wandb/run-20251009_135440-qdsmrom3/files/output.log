[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                                                                                      | 53/266 [11:46<45:47, 12.90s/it]                                       
{'loss': 0.628, 'grad_norm': 15.354645729064941, 'learning_rate': 3.3333333333333333e-06, 'rewards/chosen': 0.125, 'rewards/rejected': -0.0537109375, 'rewards/accuracies': 0.3187499940395355, 'rewards/margins': 0.1787109375, 'logps/chosen': -90.5, 'logps/rejected': -100.5, 'logits/chosen': nan, 'logits/rejected': nan, 'epoch': 0.04}
{'loss': 0.3465, 'grad_norm': 4.078766822814941, 'learning_rate': 7.0370370370370375e-06, 'rewards/chosen': 0.345703125, 'rewards/rejected': -3.828125, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 4.15625, 'logps/chosen': -91.0, 'logps/rejected': -130.0, 'logits/chosen': -4.53125, 'logits/rejected': -3.921875, 'epoch': 0.08}
{'loss': 0.3151, 'grad_norm': 9.691401481628418, 'learning_rate': 9.99827225784264e-06, 'rewards/chosen': 0.1455078125, 'rewards/rejected': -8.875, 'rewards/accuracies': 0.518750011920929, 'rewards/margins': 9.0, 'logps/chosen': -86.0, 'logps/rejected': -172.0, 'logits/chosen': -5.375, 'logits/rejected': -4.75, 'epoch': 0.11}
{'loss': 0.3024, 'grad_norm': 0.020373797044157982, 'learning_rate': 9.937926563848345e-06, 'rewards/chosen': -0.1171875, 'rewards/rejected': -12.375, 'rewards/accuracies': 0.59375, 'rewards/margins': 12.25, 'logps/chosen': -98.0, 'logps/rejected': -215.0, 'logits/chosen': -5.375, 'logits/rejected': -4.84375, 'epoch': 0.15}
{'loss': 0.3086, 'grad_norm': 0.03234585002064705, 'learning_rate': 9.792384095234312e-06, 'rewards/chosen': -0.328125, 'rewards/rejected': -16.625, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 16.25, 'logps/chosen': -85.0, 'logps/rejected': -258.0, 'logits/chosen': -6.0, 'logits/rejected': -5.53125, 'epoch': 0.19}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                                                                                      | 53/266 [12:24<45:47, 12.90s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-53                                                                
{'eval_loss': 0.33679911494255066, 'eval_runtime': 37.9055, 'eval_samples_per_second': 26.381, 'eval_steps_per_second': 0.844, 'eval_rewards/chosen': 0.98046875, 'eval_rewards/rejected': -15.125, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 16.125, 'eval_logps/chosen': -77.0, 'eval_logps/rejected': -245.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.2}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-53/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-53/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-53/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-53/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-53/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-53/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                                    | 106/266 [24:52<33:42, 12.64s/it]
{'loss': 0.3155, 'grad_norm': 0.003631983418017626, 'learning_rate': 9.56415597660634e-06, 'rewards/chosen': 0.63671875, 'rewards/rejected': -15.0625, 'rewards/accuracies': 0.546875, 'rewards/margins': 15.6875, 'logps/chosen': -84.0, 'logps/rejected': -236.0, 'logits/chosen': -5.6875, 'logits/rejected': -4.8125, 'epoch': 0.23}
{'loss': 0.2955, 'grad_norm': 0.0015658873599022627, 'learning_rate': 9.257179953763846e-06, 'rewards/chosen': -2.609375, 'rewards/rejected': -16.0, 'rewards/accuracies': 0.59375, 'rewards/margins': 13.375, 'logps/chosen': -122.5, 'logps/rejected': -258.0, 'logits/chosen': -4.78125, 'logits/rejected': -4.09375, 'epoch': 0.26}
{'loss': 0.2932, 'grad_norm': 0.6311112642288208, 'learning_rate': 8.876752453596462e-06, 'rewards/chosen': -0.07373046875, 'rewards/rejected': -17.75, 'rewards/accuracies': 0.5718749761581421, 'rewards/margins': 17.75, 'logps/chosen': -97.0, 'logps/rejected': -274.0, 'logits/chosen': -5.4375, 'logits/rejected': -4.625, 'epoch': 0.3}
{'loss': 0.3142, 'grad_norm': 0.15393806993961334, 'learning_rate': 8.429437201905254e-06, 'rewards/chosen': -0.3046875, 'rewards/rejected': -18.75, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 18.5, 'logps/chosen': -98.0, 'logps/rejected': -280.0, 'logits/chosen': -5.78125, 'logits/rejected': -4.9375, 'epoch': 0.34}
{'loss': 0.2865, 'grad_norm': 5.081958293914795, 'learning_rate': 7.92295197581581e-06, 'rewards/chosen': -1.8359375, 'rewards/rejected': -18.5, 'rewards/accuracies': 0.596875011920929, 'rewards/margins': 16.75, 'logps/chosen': -116.0, 'logps/rejected': -280.0, 'logits/chosen': -5.84375, 'logits/rejected': -5.125, 'epoch': 0.38}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                                    | 106/266 [25:30<33:42, 12.64s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-106                                                               
{'eval_loss': 0.33340856432914734, 'eval_runtime': 37.8411, 'eval_samples_per_second': 26.426, 'eval_steps_per_second': 0.846, 'eval_rewards/chosen': -0.75390625, 'eval_rewards/rejected': -15.875, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 15.125, 'eval_logps/chosen': -94.5, 'eval_logps/rejected': -253.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.4}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-106/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-106/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-106/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-106/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-106/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-106/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-53] due to args.save_total_limit
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 159/266 [38:02<22:28, 12.60s/it]
{'loss': 0.3006, 'grad_norm': 0.019406644627451897, 'learning_rate': 7.366035444706346e-06, 'rewards/chosen': -1.0390625, 'rewards/rejected': -15.8125, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 14.8125, 'logps/chosen': -101.0, 'logps/rejected': -241.0, 'logits/chosen': -5.84375, 'logits/rejected': -5.03125, 'epoch': 0.41}
{'loss': 0.3136, 'grad_norm': 6.147329258965328e-05, 'learning_rate': 6.768296397117848e-06, 'rewards/chosen': 0.1044921875, 'rewards/rejected': -15.75, 'rewards/accuracies': 0.528124988079071, 'rewards/margins': 15.8125, 'logps/chosen': -93.5, 'logps/rejected': -239.0, 'logits/chosen': -5.75, 'logits/rejected': -4.8125, 'epoch': 0.45}
{'loss': 0.3255, 'grad_norm': 0.001261447905562818, 'learning_rate': 6.140047955017672e-06, 'rewards/chosen': 0.671875, 'rewards/rejected': -16.875, 'rewards/accuracies': 0.528124988079071, 'rewards/margins': 17.625, 'logps/chosen': -93.5, 'logps/rejected': -251.0, 'logits/chosen': -5.34375, 'logits/rejected': -4.46875, 'epoch': 0.49}
{'loss': 0.3011, 'grad_norm': 0.15769171714782715, 'learning_rate': 5.492129635809473e-06, 'rewards/chosen': 0.65625, 'rewards/rejected': -19.625, 'rewards/accuracies': 0.596875011920929, 'rewards/margins': 20.375, 'logps/chosen': -96.5, 'logps/rejected': -298.0, 'logits/chosen': -5.21875, 'logits/rejected': -4.15625, 'epoch': 0.53}
{'loss': 0.307, 'grad_norm': 0.014495705254375935, 'learning_rate': 4.835720332151907e-06, 'rewards/chosen': 0.71484375, 'rewards/rejected': -17.375, 'rewards/accuracies': 0.565625011920929, 'rewards/margins': 18.125, 'logps/chosen': -81.5, 'logps/rejected': -260.0, 'logits/chosen': -5.40625, 'logits/rejected': -4.28125, 'epoch': 0.56}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 159/266 [38:40<22:28, 12.60s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-159                                                               
{'eval_loss': 0.33334487676620483, 'eval_runtime': 37.8467, 'eval_samples_per_second': 26.422, 'eval_steps_per_second': 0.846, 'eval_rewards/chosen': 0.71484375, 'eval_rewards/rejected': -19.5, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 20.25, 'eval_logps/chosen': -79.5, 'eval_logps/rejected': -290.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.6}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-159/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-159/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-159/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-159/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-159/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-159/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-106] due to args.save_total_limit
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 212/266 [51:07<11:19, 12.58s/it]
{'loss': 0.3035, 'grad_norm': 0.00887532252818346, 'learning_rate': 4.182145436348587e-06, 'rewards/chosen': 0.5625, 'rewards/rejected': -18.125, 'rewards/accuracies': 0.5218750238418579, 'rewards/margins': 18.625, 'logps/chosen': -83.0, 'logps/rejected': -268.0, 'logits/chosen': -5.46875, 'logits/rejected': -4.09375, 'epoch': 0.6}
{'loss': 0.3004, 'grad_norm': 0.019827116280794144, 'learning_rate': 3.542681437098745e-06, 'rewards/chosen': 0.81640625, 'rewards/rejected': -21.125, 'rewards/accuracies': 0.559374988079071, 'rewards/margins': 22.0, 'logps/chosen': -86.5, 'logps/rejected': -302.0, 'logits/chosen': -5.78125, 'logits/rejected': -4.8125, 'epoch': 0.64}
{'loss': 0.3065, 'grad_norm': 0.00011621821613516659, 'learning_rate': 2.9283613600087933e-06, 'rewards/chosen': 0.380859375, 'rewards/rejected': -20.875, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 21.25, 'logps/chosen': -80.0, 'logps/rejected': -294.0, 'logits/chosen': -6.21875, 'logits/rejected': -5.1875, 'epoch': 0.68}
{'loss': 0.2956, 'grad_norm': 0.00015175477892626077, 'learning_rate': 2.349784408707112e-06, 'rewards/chosen': 0.6015625, 'rewards/rejected': -22.75, 'rewards/accuracies': 0.596875011920929, 'rewards/margins': 23.375, 'logps/chosen': -100.5, 'logps/rejected': -320.0, 'logits/chosen': -5.84375, 'logits/rejected': -5.21875, 'epoch': 0.71}
{'loss': 0.2919, 'grad_norm': 0.0009590669651515782, 'learning_rate': 1.816933090929055e-06, 'rewards/chosen': 0.7578125, 'rewards/rejected': -22.5, 'rewards/accuracies': 0.5843750238418579, 'rewards/margins': 23.25, 'logps/chosen': -89.0, 'logps/rejected': -316.0, 'logits/chosen': -6.125, 'logits/rejected': -5.09375, 'epoch': 0.75}
{'loss': 0.2912, 'grad_norm': 0.00041512068128213286, 'learning_rate': 1.3390009847968505e-06, 'rewards/chosen': 0.50390625, 'rewards/rejected': -21.875, 'rewards/accuracies': 0.5718749761581421, 'rewards/margins': 22.375, 'logps/chosen': -92.0, 'logps/rejected': -312.0, 'logits/chosen': -6.09375, 'logits/rejected': -5.0625, 'epoch': 0.79}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 212/266 [51:45<11:19, 12.58s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-212                                                               
{'eval_loss': 0.33333149552345276, 'eval_runtime': 37.9635, 'eval_samples_per_second': 26.341, 'eval_steps_per_second': 0.843, 'eval_rewards/chosen': 0.33984375, 'eval_rewards/rejected': -22.25, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 22.625, 'eval_logps/chosen': -83.5, 'eval_logps/rejected': -316.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.8}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-212/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-212/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-212/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-212/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-212/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-212/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-159] due to args.save_total_limit
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 265/266 [1:04:17<00:12, 12.56s/it]
{'loss': 0.2902, 'grad_norm': 0.00022936960158403963, 'learning_rate': 9.242341169379077e-07, 'rewards/chosen': 0.90625, 'rewards/rejected': -22.0, 'rewards/accuracies': 0.559374988079071, 'rewards/margins': 22.875, 'logps/chosen': -90.0, 'logps/rejected': -308.0, 'logits/chosen': -6.125, 'logits/rejected': -5.125, 'epoch': 0.83}
{'loss': 0.3005, 'grad_norm': 8.102998253889382e-05, 'learning_rate': 5.797886892324695e-07, 'rewards/chosen': 0.65234375, 'rewards/rejected': -22.625, 'rewards/accuracies': 0.5718749761581421, 'rewards/margins': 23.25, 'logps/chosen': -89.5, 'logps/rejected': -318.0, 'logits/chosen': -6.0625, 'logits/rejected': -5.15625, 'epoch': 0.86}
{'loss': 0.3043, 'grad_norm': 2.212014442193322e-05, 'learning_rate': 3.116076089096265e-07, 'rewards/chosen': 0.2216796875, 'rewards/rejected': -22.125, 'rewards/accuracies': 0.534375011920929, 'rewards/margins': 22.375, 'logps/chosen': -81.0, 'logps/rejected': -312.0, 'logits/chosen': -5.9375, 'logits/rejected': -4.90625, 'epoch': 0.9}
{'loss': 0.3047, 'grad_norm': 0.004866511095315218, 'learning_rate': 1.2431795228615372e-07, 'rewards/chosen': 0.54296875, 'rewards/rejected': -20.5, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 21.0, 'logps/chosen': -80.5, 'logps/rejected': -284.0, 'logits/chosen': -6.0625, 'logits/rejected': -5.4375, 'epoch': 0.94}
{'loss': 0.3118, 'grad_norm': 0.001545900129713118, 'learning_rate': 2.115113126290258e-08, 'rewards/chosen': 0.470703125, 'rewards/rejected': -22.375, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 22.875, 'logps/chosen': -88.5, 'logps/rejected': -312.0, 'logits/chosen': -5.90625, 'logits/rejected': -5.09375, 'epoch': 0.98}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 265/266 [1:04:55<00:12, 12.56s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265                                                               
{'eval_loss': 0.3333311975002289, 'eval_runtime': 37.8451, 'eval_samples_per_second': 26.424, 'eval_steps_per_second': 0.846, 'eval_rewards/chosen': 0.33203125, 'eval_rewards/rejected': -22.375, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 22.625, 'eval_logps/chosen': -83.5, 'eval_logps/rejected': -318.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 1.0}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-212] due to args.save_total_limit
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:06:32<00:00, 49.33s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-266
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-266/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-266/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-266/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-266/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-266/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-266/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once


Training completed. Do not forget to share your model on huggingface.co/models =)


/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Loading best model from /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265 (score: 0.3333311975002289).
Attempting to resume from /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-265
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:07:56<00:00, 49.33s/it]Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/checkpoint-266] due to args.save_total_limit
{'train_runtime': 4079.4299, 'train_samples_per_second': 8.346, 'train_steps_per_second': 0.065, 'train_loss': 0.3171925213103904, 'epoch': 1.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:08:08<00:00, 15.37s/it]
Custom impl., saving last checkpoint
 stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/special_tokens_map.json
Processing zero checkpoint '/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1/global_step265'
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1662.92it/s]
Detected checkpoint of type zero stage ZeroStageEnum.weights, world_size: 4
Parsing checkpoint created by deepspeed==0.17.6
Gathering sharded weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 399/399 [00:00<00:00, 998524.64it/s]
Reconstructed Trainable fp32 state dict with 399 params 8188564480 elements
Saving checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [01:29<00:00, 12.78s/it]
Saved merged FP32 checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-5_b0.1
