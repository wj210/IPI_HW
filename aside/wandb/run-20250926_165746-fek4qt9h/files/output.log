wandb: Detected [huggingface_hub.inference, openai] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
  0%|          | 0/625 [00:00<?, ?it/s]
Input Text Sequence:
[('<|im_start|>system\nBelow is an instruction that describes a task, paired with an input that provides further context.\nWrite a response that appropriately completes the request.\n\nInstruction:\nName ten authors who have written works of science fiction / fantasy.\n<|im_end|>\n<|im_start|>user\n', 'inst'), ('Input:\nNo input\n<|im_end|>\n<|im_start|>assistant\n<think>\n\n</think>\n\nResponse: Here are ten authors who are well-known for their contributions to the genres of science fiction and fantasy:\n\n1. Isaac Asimov - Known for his "Foundation" series and "Robot" series.\n2. J.R.R. Tolkien - Renowned for "The Lord of the Rings" and "The Hobbit."\n3. Ursula K. Le Guin - Famous for her "Earthsea" series and "The Left Hand of Darkness."\n4. Philip K. Dick - Known for his influential works like "Do Androids Dream of Electric Sheep?" (which inspired the film "Blade Runner") and "The Man in the High Castle."\n5. Arthur C. Clarke - Notable for "2001: A Space Odyssey" and "Childhood\'s End."\n6. George R.R. Martin - Best known for "A Song of Ice and Fire," which was adapted into the television series "Game of Thrones."\n7. Frank Herbert - Author of the "Dune" series.\n8. Ray Bradbury - Known for "Fahrenheit 451" and "The Martian Chronicles."\n9. Neil Gaiman - Famous for works like "American Gods," "Coraline," and "The Sandman" comic series.\n10. Robert Jordan - Known for "The Wheel of Time" series, which has been continued by Brandon Sanderson after Jordan\'s death.\n\nThese authors have produced seminal works that have both defined and expanded the boundaries of the science fiction and fantasy genres..\n\n<|im_end|>\n', 'data')]
Prompt : <|im_start|>system
Below is an instruction that describes a task, paired with an input that provides further context.
Write a response that appropriately completes the request.

Instruction:
Name ten authors who have written works of science fiction / fantasy.
<|im_end|>
<|im_start|>user
Input:
No input
<|im_end|>
<|im_start|>assistant
<think>

</think>

Response: Here are ten authors who are well-known for their contributions to the genres of science fiction and fantasy:

1. Isaac Asimov - Known for his "Foundation" series and "Robot" series.
2. J.R.R. Tolkien - Renowned for "The Lord of the Rings" and "The Hobbit."
3. Ursula K. Le Guin - Famous for her "Earthsea" series and "The Left Hand of Darkness."
4. Philip K. Dick - Known for his influential works like "Do Androids Dream of Electric Sheep?" (which inspired the film "Blade Runner") and "The Man in the High Castle."
5. Arthur C. Clarke - Notable for "2001: A Space Odyssey" and "Childhood's End."
6. George R.R. Martin - Best known for "A Song of Ice and Fire," which was adapted into the television series "Game of Thrones."
7. Frank Herbert - Author of the "Dune" series.
8. Ray Bradbury - Known for "Fahrenheit 451" and "The Martian Chronicles."
9. Neil Gaiman - Famous for works like "American Gods," "Coraline," and "The Sandman" comic series.
10. Robert Jordan - Known for "The Wheel of Time" series, which has been continued by Brandon Sanderson after Jordan's death.

These authors have produced seminal works that have both defined and expanded the boundaries of the science fiction and fantasy genres..

<|im_end|>
<|im_end|>
  File "/export/home2/weijie210/ipi_huawei/aside/fine-tune.py", line 872, in <module>
    main(model_family, emb_type, train_version, model_ix, run_number, user_hparams)
  File "/export/home2/weijie210/ipi_huawei/aside/fine-tune.py", line 748, in main
    trainer.train()
  File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/transformers/trainer.py", line 2328, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/transformers/trainer.py", line 2623, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/transformers/trainer.py", line 5581, in get_batch_samples
    batch_samples.append(next(epoch_iterator))
                         ^^^^^^^^^^^^^^^^^^^^
  File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/accelerate/data_loader.py", line 567, in __iter__
    current_batch = next(dataloader_iter)
                    ^^^^^^^^^^^^^^^^^^^^^
  File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/export/home2/weijie210/ipi_huawei/aside/fine-tune.py", line 199, in __getitem__
    encoded = aside_encode_start(encoded,self.handler.tokenizer,assistant_start,key = 'labels')
                                 ^^^^^^^
UnboundLocalError: cannot access local variable 'encoded' where it is not associated with a value
[rank0]: Traceback (most recent call last):
[rank0]:   File "/export/home2/weijie210/ipi_huawei/aside/fine-tune.py", line 872, in <module>
[rank0]:     main(model_family, emb_type, train_version, model_ix, run_number, user_hparams)
[rank0]:   File "/export/home2/weijie210/ipi_huawei/aside/fine-tune.py", line 748, in main
[rank0]:     trainer.train()
[rank0]:   File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/transformers/trainer.py", line 2328, in train
[rank0]:     return inner_training_loop(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/transformers/trainer.py", line 2623, in _inner_training_loop
[rank0]:     batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
[rank0]:                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/transformers/trainer.py", line 5581, in get_batch_samples
[rank0]:     batch_samples.append(next(epoch_iterator))
[rank0]:                          ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/accelerate/data_loader.py", line 567, in __iter__
[rank0]:     current_batch = next(dataloader_iter)
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
[rank0]:     data = self._next_data()
[rank0]:            ^^^^^^^^^^^^^^^^^
[rank0]:   File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
[rank0]:     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/export/home2/weijie210/miniconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:             ~~~~~~~~~~~~^^^^^
[rank0]:   File "/export/home2/weijie210/ipi_huawei/aside/fine-tune.py", line 199, in __getitem__
[rank0]:     encoded = aside_encode_start(encoded,self.handler.tokenizer,assistant_start,key = 'labels')
[rank0]:                                  ^^^^^^^
[rank0]: UnboundLocalError: cannot access local variable 'encoded' where it is not associated with a value
