[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
  0%|                                                                                                                                                                               | 0/2343 [00:00<?, ?it/s]
Tool Prompt : <|im_start|>system
# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{"type": "function", "function": {"name": "mcpollinations-generateImageUrl", "description": "Generate an image URL from a text prompt", "parameters": {"type": "object", "properties": {"prompt": {"type": "string", "description": "The text description of the image to generate"}, "model": {"type": "string", "description": "Model name to use for generation (default: \"flux\"). Available options: \"flux\", \"sdxl\", \"sd3\", \"sd15\", \"flux-schnell\", \"flux-dev\""}, "seed": {"type": "number", "description": "Seed for reproducible results (default: random)"}, "width": {"type": "number", "description": "Width of the generated image (default: 1024)"}, "height": {"type": "number", "description": "Height of the generated image (default: 1024)"}, "enhance": {"type": "boolean", "description": "Whether to enhance the prompt using an LLM before generating (default: true)"}, "safe": {"type": "boolean", "description": "Whether to apply content filtering (default: false)"}}, "required": ["prompt"]}}}
{"type": "function", "function": {"name": "mcpollinations-generateImage", "description": "Generate an image, return the base64-encoded data, and save to a file by default", "parameters": {"type": "object", "properties": {"prompt": {"type": "string", "description": "The text description of the image to generate"}, "model": {"type": "string", "description": "Model name to use for generation (default: \"flux\"). Available options: \"flux, \"turbo\" (sdxl),"}, "seed": {"type": "number", "description": "Seed for reproducible results (default: random)"}, "width": {"type": "number", "description": "Width of the generated image (default: 1024)"}, "height": {"type": "number", "description": "Height of the generated image (default: 1024)"}, "enhance": {"type": "boolean", "description": "Whether to enhance the prompt using an LLM before generating (default: true)"}, "safe": {"type": "boolean", "description": "Whether to apply content filtering (default: false)"}, "outputPath": {"type": "string", "description": "Directory path where to save the image (default: \"./mcpollinations-output\")"}, "fileName": {"type": "string", "description": "Name of the file to save (without extension, default: generated from prompt)"}, "format": {"type": "string", "description": "Image format to save as (png, jpeg, jpg, webp - default: png)"}}, "required": ["prompt"]}}}
{"type": "function", "function": {"name": "mcpollinations-listImageModels", "description": "List available image models", "parameters": {"type": "object", "properties": {}}}}
{"type": "function", "function": {"name": "mcpollinations-respondAudio", "description": "Generate an audio response to a text prompt and play it through the system", "parameters": {"type": "object", "properties": {"prompt": {"type": "string", "description": "The text prompt to respond to with audio"}, "voice": {"type": "string", "description": "Voice to use for audio generation (default: \"alloy\"). Available options: \"alloy\", \"echo\", \"fable\", \"onyx\", \"nova\", \"shimmer\", \"coral\", \"verse\", \"ballad\", \"ash\", \"sage\", \"amuch\", \"dan\""}, "seed": {"type": "number", "description": "Seed for reproducible results (default: random)"}}, "required": ["prompt"]}}}
{"type": "function", "function": {"name": "mcpollinations-listAudioVoices", "description": "List all available audio voices for text-to-speech generation", "parameters": {"type": "object", "properties": {}}}}
{"type": "function", "function": {"name": "mcpollinations-respondText", "description": "Respond with text to a prompt using the Pollinations Text API", "parameters": {"type": "object", "properties": {"prompt": {"type": "string", "description": "The text prompt to generate a response for"}, "model": {"type": "string", "description": "Model to use for text generation (default: \"openai\"). Available options: \"openai\", \"anthropic\", \"mistral\", \"llama\", \"gemini\" - use listTextModels to see all models"}, "seed": {"type": "number", "description": "Seed for reproducible results (default: random)"}}, "required": ["prompt"]}}}
{"type": "function", "function": {"name": "mcpollinations-listTextModels", "description": "List available text models", "parameters": {"type": "object", "properties": {}}}}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call><|im_end|>
<|im_start|>user
I'm designing a marketing campaign for a boutique restaurant and need a highâ€‘resolution illustration of an elegant plated entrÃ©e: a seared scallop perched on a silky cauliflower purÃ©e, drizzled with a citrusâ€‘infused beurre blanc, garnished with microâ€‘herbs and edible gold flakes, presented on a dark slate charger under soft spotlighting. I want to save this as a highâ€‘quality image file on my computer so I can incorporate it directly into the campaign's visual assetsâ€”can you generate this scene and save it for me?<|im_end|>
<|im_start|>assistant
<think>

</think>

<tool_call>
{"name": "mcpollinations-generateImage", "arguments": {"prompt": "an elegant plated entrÃ©e: a seared scallop perched on a silky cauliflower purÃ©e, drizzled with a citrus-infused beurre blanc, garnished with micro-herbs and edible gold flakes, presented on a dark slate charger under soft spotlighting", "model": "sdxl", "width": 3000, "height": 2000, "enhance": true, "safe": false, "outputPath": "./mcpollinations-output", "fileName": "elegant_plated_entrÃ©e", "format": "png"}}
</tool_call><|im_end|>

----------------------------------------------------------------------------------------------------------------------------------------------------------------
Assistant loss chunk 0: <|im_start|>assistant
<think>

</think>

<tool_call>
{"name": "mcpollinations-generateImage", "arguments": {"prompt": "an elegant plated entrÃ©e: a seared scallop perched on a silky cauliflower purÃ©e, drizzled with a citrus-infused beurre blanc, garnished with micro-herbs and edible gold flakes, presented on a dark slate charger under soft spotlighting", "model": "sdxl", "width": 3000, "height": 2000, "enhance": true, "safe": false, "outputPath": "./mcpollinations-output", "fileName": "elegant_plated_entrÃ©e", "format": "png"}}
</tool_call><|im_end|>
----------------------------------------------------------------------------------------------------------------------------------------------------------------
Input Prompt : <|im_start|>user
Rearrange these letters to make a meaningful word.<|im_end|>
<|im_start|>user
<reference_data>
vnrie
</reference_data><|im_end|>
<|im_start|>assistant
<think>

</think>

To solve the anagram **vnrie**, let's go through the process step by step.

### Step 1: Analyze the letters
We have the letters: **v, n, r, i, e**.

### Step 2: Look for possible word patterns
We are looking for a meaningful English word using all five letters. Let's consider possible combinations.

### Step 3: Try rearranging
Letâ€™s try different combinations:

- **river** â€“ This uses all the letters: **r, i, v, e, r**. Wait, we only have one **r** in the original letters. So **river** is not possible.

- **riven** â€“ This is a valid word. Let's check the letters:
  - **r, i, v, e, n** â€“ Yes, that's exactly the letters we have.

### Step 4: Confirm the word
**Riven** is a valid English word. It means:
- **Past tense of "rave"** â€“ though this is less common.
- **To be split or divided** â€“ more commonly used in a metaphorical sense.

### âœ… Final Answer:
**riven**<|im_end|>

Rotated chunk 0:
<|im_start|>user
<reference_data>
vnrie
</reference_data><|im_end|>
<|im_start|>assistant
<think>

</think>

To solve the anagram **vnrie**, let's go through the process step by step.

### Step 1: Analyze the letters
We have the letters: **v, n, r, i, e**.

### Step 2: Look for possible word patterns
We are looking for a meaningful English word using all five letters. Let's consider possible combinations.

### Step 3: Try rearranging
Letâ€™s try different combinations:

- **river** â€“ This uses all the letters: **r, i, v, e, r**. Wait, we only have one **r** in the original letters. So **river** is not possible.

- **riven** â€“ This is a valid word. Let's check the letters:
  - **r, i, v, e, n** â€“ Yes, that's exactly the letters we have.

### Step 4: Confirm the word
**Riven** is a valid English word. It means:
- **Past tense of "rave"** â€“ though this is less common.
- **To be split or divided** â€“ more commonly used in a metaphorical sense.

### âœ… Final Answer:
**riven**<|im_end|>
----------------------------------------------------------------------------------------------------------------------------------------------------------------
                                                                                                                                                                                                             
[2025-10-14 03:57:49,019] [WARNING] [stage3.py:2171:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
[2025-10-14 03:58:12,086] [WARNING] [stage3.py:2171:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3927, 'grad_norm': 8.668014526367188, 'learning_rate': 9.574468085106384e-07, 'epoch': 0.0}
{'loss': 0.2568, 'grad_norm': 3.831315517425537, 'learning_rate': 2.021276595744681e-06, 'epoch': 0.01}
{'loss': 0.1551, 'grad_norm': 1.8958879709243774, 'learning_rate': 3.0851063829787237e-06, 'epoch': 0.01}
{'loss': 0.1295, 'grad_norm': 1.2022026777267456, 'learning_rate': 4.148936170212766e-06, 'epoch': 0.02}
{'loss': 0.1214, 'grad_norm': 1.5504566431045532, 'learning_rate': 5.212765957446809e-06, 'epoch': 0.02}
{'loss': 0.1122, 'grad_norm': 1.4196797609329224, 'learning_rate': 6.276595744680851e-06, 'epoch': 0.03}
{'loss': 0.1093, 'grad_norm': 1.3945353031158447, 'learning_rate': 7.340425531914894e-06, 'epoch': 0.03}
{'loss': 0.1059, 'grad_norm': 1.6640950441360474, 'learning_rate': 8.404255319148937e-06, 'epoch': 0.03}
{'loss': 0.1094, 'grad_norm': 1.3501970767974854, 'learning_rate': 9.46808510638298e-06, 'epoch': 0.04}
{'loss': 0.11, 'grad_norm': 1.361600637435913, 'learning_rate': 9.99987804514719e-06, 'epoch': 0.04}
{'loss': 0.1129, 'grad_norm': 1.45662522315979, 'learning_rate': 9.99890244201959e-06, 'epoch': 0.05}
{'loss': 0.1188, 'grad_norm': 1.324471354484558, 'learning_rate': 9.996951426129327e-06, 'epoch': 0.05}
{'loss': 0.114, 'grad_norm': 1.4239541292190552, 'learning_rate': 9.994025378169123e-06, 'epoch': 0.06}
{'loss': 0.1178, 'grad_norm': 1.3734233379364014, 'learning_rate': 9.990124869085216e-06, 'epoch': 0.06}
{'loss': 0.1237, 'grad_norm': 1.304836392402649, 'learning_rate': 9.98525065996594e-06, 'epoch': 0.06}
[2025-10-14 04:53:08,119] [WARNING] [stage3.py:2171:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.1153, 'grad_norm': 1.3721708059310913, 'learning_rate': 9.979403701893226e-06, 'epoch': 0.07}
{'loss': 0.1164, 'grad_norm': 1.4757637977600098, 'learning_rate': 9.97258513575702e-06, 'epoch': 0.07}
{'loss': 0.1181, 'grad_norm': 1.5176335573196411, 'learning_rate': 9.96479629203266e-06, 'epoch': 0.08}
[2025-10-14 05:05:08,624] [WARNING] [stage3.py:2171:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.1177, 'grad_norm': 1.4109152555465698, 'learning_rate': 9.956038690521276e-06, 'epoch': 0.08}
{'loss': 0.1144, 'grad_norm': 1.3739444017410278, 'learning_rate': 9.946314040053234e-06, 'epoch': 0.09}
{'loss': 0.1129, 'grad_norm': 1.4988282918930054, 'learning_rate': 9.935624238154696e-06, 'epoch': 0.09}
{'loss': 0.1222, 'grad_norm': 1.3681763410568237, 'learning_rate': 9.923971370677375e-06, 'epoch': 0.09}
{'loss': 0.1196, 'grad_norm': 1.3658066987991333, 'learning_rate': 9.911357711391519e-06, 'epoch': 0.1}
{'loss': 0.1202, 'grad_norm': 1.3313804864883423, 'learning_rate': 9.89778572154225e-06, 'epoch': 0.1}
{'loss': 0.1216, 'grad_norm': 1.416568398475647, 'learning_rate': 9.883258049369313e-06, 'epoch': 0.11}
{'loss': 0.1234, 'grad_norm': 1.3507256507873535, 'learning_rate': 9.86777752959033e-06, 'epoch': 0.11}
{'loss': 0.1174, 'grad_norm': 1.3482730388641357, 'learning_rate': 9.851347182847678e-06, 'epoch': 0.12}
{'loss': 0.1213, 'grad_norm': 1.3375362157821655, 'learning_rate': 9.833970215119088e-06, 'epoch': 0.12}
{'loss': 0.1194, 'grad_norm': 1.2940784692764282, 'learning_rate': 9.815650017092078e-06, 'epoch': 0.12}
{'loss': 0.1225, 'grad_norm': 1.4571545124053955, 'learning_rate': 9.796390163502334e-06, 'epoch': 0.13}
{'loss': 0.1233, 'grad_norm': 1.2851784229278564, 'learning_rate': 9.776194412436202e-06, 'epoch': 0.13}
{'loss': 0.1198, 'grad_norm': 1.4090901613235474, 'learning_rate': 9.75506670459738e-06, 'epoch': 0.14}
{'loss': 0.1228, 'grad_norm': 1.2605324983596802, 'learning_rate': 9.73301116253799e-06, 'epoch': 0.14}
{'loss': 0.1159, 'grad_norm': 1.2325702905654907, 'learning_rate': 9.710032089854166e-06, 'epoch': 0.15}
{'loss': 0.1151, 'grad_norm': 1.2740072011947632, 'learning_rate': 9.686133970346305e-06, 'epoch': 0.15}
{'loss': 0.1217, 'grad_norm': 1.2924394607543945, 'learning_rate': 9.661321467144172e-06, 'epoch': 0.15}
{'loss': 0.1197, 'grad_norm': 1.2982677221298218, 'learning_rate': 9.635599421797004e-06, 'epoch': 0.16}
{'loss': 0.124, 'grad_norm': 1.3354277610778809, 'learning_rate': 9.6089728533288e-06, 'epoch': 0.16}
{'loss': 0.1235, 'grad_norm': 1.2248578071594238, 'learning_rate': 9.581446957258975e-06, 'epoch': 0.17}
{'loss': 0.1201, 'grad_norm': 1.33661949634552, 'learning_rate': 9.553027104588593e-06, 'epoch': 0.17}
{'loss': 0.1202, 'grad_norm': 1.2646833658218384, 'learning_rate': 9.523718840752343e-06, 'epoch': 0.18}
{'loss': 0.116, 'grad_norm': 1.2834926843643188, 'learning_rate': 9.493527884536487e-06, 'epoch': 0.18}
{'loss': 0.1259, 'grad_norm': 1.3283783197402954, 'learning_rate': 9.46246012696297e-06, 'epoch': 0.18}
{'loss': 0.1176, 'grad_norm': 1.3071571588516235, 'learning_rate': 9.430521630139946e-06, 'epoch': 0.19}
[2025-10-14 06:35:35,197] [WARNING] [stage3.py:2171:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.1181, 'grad_norm': 1.278443694114685, 'learning_rate': 9.3977186260789e-06, 'epoch': 0.19}
{'loss': 0.1189, 'grad_norm': 1.2969694137573242, 'learning_rate': 9.36405751547862e-06, 'epoch': 0.2}
***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
Tool Prompt : <|im_start|>user
Suggest three cities in California that could be great for a family vacation.<|im_end|>
<|im_start|>assistant
<think>

</think>

Certainly! California offers a wide variety of cities that are perfect for a family vacation, with something to suit every age and interest. Here are three great options:

### 1. **San Diego**
- **Why it's great for families:** San Diego is known for its mild climate, beautiful beaches, and family-friendly attractions.
- **Top attractions:**
  - **San Diego Zoo:** One of the world's most famous zoos, home to thousands of animals.
  - **Balboa Park:** Features museums, gardens, and the world's largest urban park.
  - **La Jolla Cove:** A scenic beach with great snorkeling and tide pool exploration.
  - **Children's Museum of San Diego:** Interactive exhibits for kids of all ages.
- **Family-friendly activities:** Beaches, outdoor adventures, and cultural experiences.

### 2. **Los Angeles**
- **Why it's great for families:** LA offers a mix of entertainment, culture, and outdoor activities, with plenty of options for all ages.
- **Top attractions:**
  - **Griffith Observatory:** Offers stunning views of the city and the Hollywood sign, plus educational exhibits.
  - **Santa Monica Pier:** A fun spot with rides, games, and the famous Ferris wheel.
  - **Disneyland Resort (Anaheim):** Just a short drive away, it's a must-visit for families with kids.
  - **The Getty Center:** A beautiful museum with art and gardens.
- **Family-friendly activities:** Theme parks, museums, and beach days.

### 3. **Sacramento**
- **Why it's great for families:** As the capital of California, Sacramento offers a mix of history, culture, and family-friendly attractions without the crowds of larger cities.
- **Top attractions:**
  - **California State Capitol Museum:** Offers a fascinating look into the state's history and government.
  - **Sutterâ€™s Fort State Historic Park:** A living history museum with costumed interpreters and interactive exhibits.
  - **Discovery Childrenâ€™s Museum:** A hands-on museum designed for young children.
  - **Sacramento Riverwalk:** A scenic path along the river with great views and picnic spots.
- **Family-friendly activities:** History, museums, and outdoor exploration.

Each of these cities offers a unique experience, so depending on your family's interests, you can choose the one that best fits your vacation goals.<|im_end|>

----------------------------------------------------------------------------------------------------------------------------------------------------------------
Assistant loss chunk 0: <|im_start|>assistant
<think>

</think>

Certainly! California offers a wide variety of cities that are perfect for a family vacation, with something to suit every age and interest. Here are three great options:

### 1. **San Diego**
- **Why it's great for families:** San Diego is known for its mild climate, beautiful beaches, and family-friendly attractions.
- **Top attractions:**
  - **San Diego Zoo:** One of the world's most famous zoos, home to thousands of animals.
  - **Balboa Park:** Features museums, gardens, and the world's largest urban park.
  - **La Jolla Cove:** A scenic beach with great snorkeling and tide pool exploration.
  - **Children's Museum of San Diego:** Interactive exhibits for kids of all ages.
- **Family-friendly activities:** Beaches, outdoor adventures, and cultural experiences.

### 2. **Los Angeles**
- **Why it's great for families:** LA offers a mix of entertainment, culture, and outdoor activities, with plenty of options for all ages.
- **Top attractions:**
  - **Griffith Observatory:** Offers stunning views of the city and the Hollywood sign, plus educational exhibits.
  - **Santa Monica Pier:** A fun spot with rides, games, and the famous Ferris wheel.
  - **Disneyland Resort (Anaheim):** Just a short drive away, it's a must-visit for families with kids.
  - **The Getty Center:** A beautiful museum with art and gardens.
- **Family-friendly activities:** Theme parks, museums, and beach days.

### 3. **Sacramento**
- **Why it's great for families:** As the capital of California, Sacramento offers a mix of history, culture, and family-friendly attractions without the crowds of larger cities.
- **Top attractions:**
  - **California State Capitol Museum:** Offers a fascinating look into the state's history and government.
  - **Sutterâ€™s Fort State Historic Park:** A living history museum with costumed interpreters and interactive exhibits.
  - **Discovery Childrenâ€™s Museum:** A hands-on museum designed for young children.
  - **Sacramento Riverwalk:** A scenic path along the river with great views and picnic spots.
- **Family-friendly activities:** History, museums, and outdoor exploration.

Each of these cities offers a unique experience, so depending on your family's interests, you can choose the one that best fits your vacation goals.<|im_end|>
----------------------------------------------------------------------------------------------------------------------------------------------------------------
Input Prompt : <|im_start|>user
Generate a response that expresses sympathy<|im_end|>
<|im_start|>user
<reference_data>
Situation: Your friend's pet died
</reference_data><|im_end|>
<|im_start|>assistant
<think>

</think>

I'm so sorry to hear about your friend's loss. Losing a pet is incredibly painful, as they become such a cherished part of our lives. I hope your friend finds comfort in the happy memories they shared with their beloved pet, and that they're able to heal over time. Let them know they're not alone in this griefâ€”it's a sign of how much their pet meant to them.<|im_end|>

Rotated chunk 0:
<|im_start|>user
<reference_data>
Situation: Your friend's pet died
</reference_data><|im_end|>
<|im_start|>assistant
<think>

</think>

I'm so sorry to hear about your friend's loss. Losing a pet is incredibly painful, as they become such a cherished part of our lives. I hope your friend finds comfort in the happy memories they shared with their beloved pet, and that they're able to heal over time. Let them know they're not alone in this griefâ€”it's a sign of how much their pet meant to them.<|im_end|>
----------------------------------------------------------------------------------------------------------------------------------------------------------------
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                                | 468/2343 [2:46:30<10:43:01, 20.58s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-468                                                                                                       
{'eval_loss': 0.1277318149805069, 'eval_runtime': 57.5939, 'eval_samples_per_second': 26.044, 'eval_steps_per_second': 0.816, 'epoch': 0.2}
Configuration saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-468/config.json
Configuration saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-468/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-468/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-468/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-468/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-468/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
                                                                                                                                                                                                             
{'loss': 0.1188, 'grad_norm': 1.213738203048706, 'learning_rate': 9.329544866476265e-06, 'epoch': 0.2}
{'loss': 0.1233, 'grad_norm': 1.2466483116149902, 'learning_rate': 9.294187413365755e-06, 'epoch': 0.2}
{'loss': 0.1212, 'grad_norm': 1.1887574195861816, 'learning_rate': 9.257992055283735e-06, 'epoch': 0.21}
{'loss': 0.1272, 'grad_norm': 1.269069790840149, 'learning_rate': 9.220965854863375e-06, 'epoch': 0.21}
{'loss': 0.1204, 'grad_norm': 1.2834382057189941, 'learning_rate': 9.183116036856283e-06, 'epoch': 0.22}
{'loss': 0.1203, 'grad_norm': 1.3384250402450562, 'learning_rate': 9.144449986722764e-06, 'epoch': 0.22}
{'loss': 0.1182, 'grad_norm': 1.274034857749939, 'learning_rate': 9.104975249190728e-06, 'epoch': 0.23}
{'loss': 0.1211, 'grad_norm': 1.2661681175231934, 'learning_rate': 9.064699526783527e-06, 'epoch': 0.23}
{'loss': 0.1135, 'grad_norm': 1.243194580078125, 'learning_rate': 9.023630678316994e-06, 'epoch': 0.23}
{'loss': 0.1174, 'grad_norm': 1.2897255420684814, 'learning_rate': 8.981776717365991e-06, 'epoch': 0.24}
{'loss': 0.1188, 'grad_norm': 1.527214527130127, 'learning_rate': 8.939145810700755e-06, 'epoch': 0.24}
{'loss': 0.1229, 'grad_norm': 1.3917160034179688, 'learning_rate': 8.895746276693354e-06, 'epoch': 0.25}
{'loss': 0.1216, 'grad_norm': 1.3145992755889893, 'learning_rate': 8.85158658369456e-06, 'epoch': 0.25}
{'loss': 0.1202, 'grad_norm': 1.2742398977279663, 'learning_rate': 8.806675348381465e-06, 'epoch': 0.26}
{'loss': 0.118, 'grad_norm': 1.2095764875411987, 'learning_rate': 8.76102133407614e-06, 'epoch': 0.26}
{'loss': 0.1187, 'grad_norm': 1.2472094297409058, 'learning_rate': 8.714633449035699e-06, 'epoch': 0.26}
{'loss': 0.1159, 'grad_norm': 1.3726849555969238, 'learning_rate': 8.667520744714055e-06, 'epoch': 0.27}
{'loss': 0.1229, 'grad_norm': 1.2654054164886475, 'learning_rate': 8.619692413995775e-06, 'epoch': 0.27}
{'loss': 0.1215, 'grad_norm': 1.2913038730621338, 'learning_rate': 8.571157789402292e-06, 'epoch': 0.28}
{'loss': 0.1183, 'grad_norm': 1.2006651163101196, 'learning_rate': 8.521926341270908e-06, 'epoch': 0.28}
{'loss': 0.119, 'grad_norm': 1.2934932708740234, 'learning_rate': 8.472007675906883e-06, 'epoch': 0.29}
{'loss': 0.1218, 'grad_norm': 1.2025437355041504, 'learning_rate': 8.42141153370901e-06, 'epoch': 0.29}
{'loss': 0.1128, 'grad_norm': 1.2365849018096924, 'learning_rate': 8.370147787269001e-06, 'epoch': 0.29}
{'loss': 0.1146, 'grad_norm': 1.3153575658798218, 'learning_rate': 8.318226439445107e-06, 'epoch': 0.3}
{'loss': 0.1194, 'grad_norm': 1.3624528646469116, 'learning_rate': 8.265657621410308e-06, 'epoch': 0.3}
{'loss': 0.1231, 'grad_norm': 1.3556207418441772, 'learning_rate': 8.212451590675445e-06, 'epoch': 0.31}
{'loss': 0.1169, 'grad_norm': 1.1769657135009766, 'learning_rate': 8.158618729087746e-06, 'epoch': 0.31}
{'loss': 0.1173, 'grad_norm': 1.3921207189559937, 'learning_rate': 8.10416954080504e-06, 'epoch': 0.32}
{'loss': 0.1145, 'grad_norm': 1.0863196849822998, 'learning_rate': 8.049114650246149e-06, 'epoch': 0.32}
{'loss': 0.1229, 'grad_norm': 1.2811540365219116, 'learning_rate': 7.993464800017774e-06, 'epoch': 0.32}
{'loss': 0.123, 'grad_norm': 1.3151363134384155, 'learning_rate': 7.937230848818355e-06, 'epoch': 0.33}
{'loss': 0.1201, 'grad_norm': 1.153854489326477, 'learning_rate': 7.880423769319265e-06, 'epoch': 0.33}
{'loss': 0.1101, 'grad_norm': 1.245654821395874, 'learning_rate': 7.823054646023749e-06, 'epoch': 0.34}
{'loss': 0.1186, 'grad_norm': 1.19636070728302, 'learning_rate': 7.765134673104065e-06, 'epoch': 0.34}
{'loss': 0.1097, 'grad_norm': 1.1937007904052734, 'learning_rate': 7.70667515221722e-06, 'epoch': 0.35}
{'loss': 0.1152, 'grad_norm': 1.202968955039978, 'learning_rate': 7.647687490299723e-06, 'epoch': 0.35}
{'loss': 0.1185, 'grad_norm': 1.259650707244873, 'learning_rate': 7.588183197341805e-06, 'epoch': 0.35}
{'loss': 0.1144, 'grad_norm': 1.0687792301177979, 'learning_rate': 7.5281738841415256e-06, 'epoch': 0.36}
{'loss': 0.1155, 'grad_norm': 1.2692722082138062, 'learning_rate': 7.467671260039218e-06, 'epoch': 0.36}
{'loss': 0.1143, 'grad_norm': 1.1506013870239258, 'learning_rate': 7.406687130632692e-06, 'epoch': 0.37}
{'loss': 0.1146, 'grad_norm': 1.269484281539917, 'learning_rate': 7.345233395473664e-06, 'epoch': 0.37}
{'loss': 0.1143, 'grad_norm': 1.4808202981948853, 'learning_rate': 7.2833220457458596e-06, 'epoch': 0.38}
{'loss': 0.1153, 'grad_norm': 1.2710754871368408, 'learning_rate': 7.220965161925215e-06, 'epoch': 0.38}
{'loss': 0.1162, 'grad_norm': 1.4309378862380981, 'learning_rate': 7.158174911422685e-06, 'epoch': 0.38}
{'loss': 0.1121, 'grad_norm': 1.3157076835632324, 'learning_rate': 7.094963546210059e-06, 'epoch': 0.39}
{'loss': 0.1113, 'grad_norm': 1.1991031169891357, 'learning_rate': 7.0313434004293015e-06, 'epoch': 0.39}
{'loss': 0.1106, 'grad_norm': 1.2838327884674072, 'learning_rate': 6.967326887985837e-06, 'epoch': 0.4}
***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 936/2343 [5:33:35<8:20:30, 21.34s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-936
{'eval_loss': 0.12060463428497314, 'eval_runtime': 57.5082, 'eval_samples_per_second': 26.083, 'eval_steps_per_second': 0.817, 'epoch': 0.4}
Configuration saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-936/config.json
Configuration saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-936/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-936/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-936/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-936/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-936/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-468] due to args.save_total_limit
                                                                                                   
{'loss': 0.1165, 'grad_norm': 1.3068788051605225, 'learning_rate': 6.902926500126292e-06, 'epoch': 0.4}
{'loss': 0.1148, 'grad_norm': 1.2684006690979004, 'learning_rate': 6.838154803001131e-06, 'epoch': 0.41}
{'loss': 0.1158, 'grad_norm': 1.3590770959854126, 'learning_rate': 6.773024435212678e-06, 'epoch': 0.41}
{'loss': 0.1107, 'grad_norm': 1.205037236213684, 'learning_rate': 6.707548105349016e-06, 'epoch': 0.41}
{'loss': 0.1127, 'grad_norm': 1.200834035873413, 'learning_rate': 6.641738589504202e-06, 'epoch': 0.42}
{'loss': 0.1103, 'grad_norm': 1.4745373725891113, 'learning_rate': 6.575608728785341e-06, 'epoch': 0.42}
{'loss': 0.1151, 'grad_norm': 1.146187424659729, 'learning_rate': 6.509171426806954e-06, 'epoch': 0.43}
{'loss': 0.1126, 'grad_norm': 1.182745099067688, 'learning_rate': 6.442439647173155e-06, 'epoch': 0.43}
{'loss': 0.1057, 'grad_norm': 1.1937570571899414, 'learning_rate': 6.375426410948128e-06, 'epoch': 0.44}
{'loss': 0.1136, 'grad_norm': 1.2213820219039917, 'learning_rate': 6.308144794115374e-06, 'epoch': 0.44}
{'loss': 0.1072, 'grad_norm': 1.3535603284835815, 'learning_rate': 6.240607925026271e-06, 'epoch': 0.44}
{'loss': 0.1134, 'grad_norm': 1.1799967288970947, 'learning_rate': 6.17282898183839e-06, 'epoch': 0.45}
{'loss': 0.1051, 'grad_norm': 1.0806691646575928, 'learning_rate': 6.104821189944102e-06, 'epoch': 0.45}
{'loss': 0.1113, 'grad_norm': 1.166792869567871, 'learning_rate': 6.036597819389972e-06, 'epoch': 0.46}
{'loss': 0.11, 'grad_norm': 1.2749378681182861, 'learning_rate': 5.968172182287433e-06, 'epoch': 0.46}
{'loss': 0.1121, 'grad_norm': 1.216915249824524, 'learning_rate': 5.899557630215256e-06, 'epoch': 0.47}
{'loss': 0.1126, 'grad_norm': 1.2057695388793945, 'learning_rate': 5.830767551614316e-06, 'epoch': 0.47}
{'loss': 0.1096, 'grad_norm': 1.2869924306869507, 'learning_rate': 5.761815369175175e-06, 'epoch': 0.47}
{'loss': 0.1055, 'grad_norm': 1.339698314666748, 'learning_rate': 5.692714537218963e-06, 'epoch': 0.48}
{'loss': 0.1066, 'grad_norm': 1.0866949558258057, 'learning_rate': 5.623478539072106e-06, 'epoch': 0.48}
{'loss': 0.1079, 'grad_norm': 1.2906839847564697, 'learning_rate': 5.5541208844353875e-06, 'epoch': 0.49}
{'loss': 0.0991, 'grad_norm': 1.3183510303497314, 'learning_rate': 5.4846551067478595e-06, 'epoch': 0.49}
{'loss': 0.1066, 'grad_norm': 1.2303704023361206, 'learning_rate': 5.4150947605461225e-06, 'epoch': 0.5}
{'loss': 0.1125, 'grad_norm': 1.245549201965332, 'learning_rate': 5.345453418819499e-06, 'epoch': 0.5}
{'loss': 0.1049, 'grad_norm': 1.2132370471954346, 'learning_rate': 5.275744670361591e-06, 'epoch': 0.5}
{'loss': 0.1082, 'grad_norm': 1.2712520360946655, 'learning_rate': 5.205982117118768e-06, 'epoch': 0.51}
{'loss': 0.1051, 'grad_norm': 1.212835431098938, 'learning_rate': 5.136179371536076e-06, 'epoch': 0.51}
{'loss': 0.1086, 'grad_norm': 1.270420789718628, 'learning_rate': 5.066350053901109e-06, 'epoch': 0.52}
{'loss': 0.108, 'grad_norm': 1.3931221961975098, 'learning_rate': 4.996507789686342e-06, 'epoch': 0.52}
{'loss': 0.0994, 'grad_norm': 1.1241471767425537, 'learning_rate': 4.926666206890457e-06, 'epoch': 0.53}
{'loss': 0.1038, 'grad_norm': 1.4048125743865967, 'learning_rate': 4.856838933379171e-06, 'epoch': 0.53}
{'loss': 0.1046, 'grad_norm': 1.246421456336975, 'learning_rate': 4.7870395942261005e-06, 'epoch': 0.53}
{'loss': 0.1036, 'grad_norm': 1.384881615638733, 'learning_rate': 4.717281809054159e-06, 'epoch': 0.54}
{'loss': 0.1091, 'grad_norm': 1.2448610067367554, 'learning_rate': 4.647579189378019e-06, 'epoch': 0.54}
{'loss': 0.0995, 'grad_norm': 1.3042104244232178, 'learning_rate': 4.577945335948172e-06, 'epoch': 0.55}
{'loss': 0.1036, 'grad_norm': 1.285534381866455, 'learning_rate': 4.508393836097061e-06, 'epoch': 0.55}
{'loss': 0.1046, 'grad_norm': 1.0853567123413086, 'learning_rate': 4.438938261087859e-06, 'epoch': 0.55}
{'loss': 0.1001, 'grad_norm': 1.2019928693771362, 'learning_rate': 4.36959216346637e-06, 'epoch': 0.56}
{'loss': 0.105, 'grad_norm': 1.1519631147384644, 'learning_rate': 4.3003690744165765e-06, 'epoch': 0.56}
{'loss': 0.1015, 'grad_norm': 1.2218669652938843, 'learning_rate': 4.231282501120366e-06, 'epoch': 0.57}
{'loss': 0.1007, 'grad_norm': 1.3284682035446167, 'learning_rate': 4.162345924121941e-06, 'epoch': 0.57}
{'loss': 0.0972, 'grad_norm': 1.2365214824676514, 'learning_rate': 4.0935727946974176e-06, 'epoch': 0.58}
{'loss': 0.1017, 'grad_norm': 1.318001627922058, 'learning_rate': 4.024976532230135e-06, 'epoch': 0.58}
{'loss': 0.0976, 'grad_norm': 1.2393077611923218, 'learning_rate': 3.95657052159221e-06, 'epoch': 0.58}
{'loss': 0.0958, 'grad_norm': 1.298275351524353, 'learning_rate': 3.888368110532788e-06, 'epoch': 0.59}
{'loss': 0.099, 'grad_norm': 1.2588543891906738, 'learning_rate': 3.820382607073575e-06, 'epoch': 0.59}
{'loss': 0.0958, 'grad_norm': 1.1612184047698975, 'learning_rate': 3.7526272769120933e-06, 'epoch': 0.6}
***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                   | 1404/2343 [8:27:08<5:35:47, 21.46s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-1404                                                                                                             
{'eval_loss': 0.10514001548290253, 'eval_runtime': 57.4577, 'eval_samples_per_second': 26.106, 'eval_steps_per_second': 0.818, 'epoch': 0.6}
Configuration saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-1404/config.json
Configuration saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-1404/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-1404/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-1404/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-1404/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-1404/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/Qwen3-8B_sft_ISE_ToolAndAlpaca_LARGE/checkpoint-936] due to args.save_total_limit
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                            | 1688/2343 [10:13:05<4:03:16, 22.29s/it]        
{'loss': 0.0985, 'grad_norm': 1.2158293724060059, 'learning_rate': 3.685115340833215e-06, 'epoch': 0.6}
{'loss': 0.0959, 'grad_norm': 1.179625153541565, 'learning_rate': 3.6178599721294476e-06, 'epoch': 0.61}
{'loss': 0.1009, 'grad_norm': 1.0870287418365479, 'learning_rate': 3.5508742940304893e-06, 'epoch': 0.61}
{'loss': 0.0956, 'grad_norm': 1.1072461605072021, 'learning_rate': 3.484171377142559e-06, 'epoch': 0.61}
{'loss': 0.1003, 'grad_norm': 1.1797086000442505, 'learning_rate': 3.417764236897979e-06, 'epoch': 0.62}
{'loss': 0.0951, 'grad_norm': 1.1855608224868774, 'learning_rate': 3.3516658310155493e-06, 'epoch': 0.62}
{'loss': 0.0925, 'grad_norm': 1.1450024843215942, 'learning_rate': 3.285889056972148e-06, 'epoch': 0.63}
{'loss': 0.0949, 'grad_norm': 1.246118187904358, 'learning_rate': 3.220446749486128e-06, 'epoch': 0.63}
{'loss': 0.0942, 'grad_norm': 1.116422176361084, 'learning_rate': 3.1553516780129157e-06, 'epoch': 0.64}
{'loss': 0.0934, 'grad_norm': 1.2920831441879272, 'learning_rate': 3.090616544253385e-06, 'epoch': 0.64}
{'loss': 0.0962, 'grad_norm': 1.0478992462158203, 'learning_rate': 3.026253979675421e-06, 'epoch': 0.64}
{'loss': 0.0906, 'grad_norm': 1.3096652030944824, 'learning_rate': 2.962276543049204e-06, 'epoch': 0.65}
{'loss': 0.0921, 'grad_norm': 1.4542768001556396, 'learning_rate': 2.898696717996678e-06, 'epoch': 0.65}
{'loss': 0.095, 'grad_norm': 1.131264090538025, 'learning_rate': 2.8355269105556695e-06, 'epoch': 0.66}
{'loss': 0.0972, 'grad_norm': 1.1754564046859741, 'learning_rate': 2.7727794467591682e-06, 'epoch': 0.66}
{'loss': 0.0974, 'grad_norm': 1.2507052421569824, 'learning_rate': 2.7104665702301895e-06, 'epoch': 0.67}
{'loss': 0.0939, 'grad_norm': 1.3867712020874023, 'learning_rate': 2.64860043979275e-06, 'epoch': 0.67}
{'loss': 0.0928, 'grad_norm': 1.224048137664795, 'learning_rate': 2.5871931270993533e-06, 'epoch': 0.67}
{'loss': 0.0913, 'grad_norm': 1.0833704471588135, 'learning_rate': 2.526256614275524e-06, 'epoch': 0.68}
{'loss': 0.0885, 'grad_norm': 1.134706974029541, 'learning_rate': 2.4658027915817717e-06, 'epoch': 0.68}
{'loss': 0.0913, 'grad_norm': 1.23787522315979, 'learning_rate': 2.4058434550935163e-06, 'epoch': 0.69}
{'loss': 0.0958, 'grad_norm': 1.1226398944854736, 'learning_rate': 2.3463903043993643e-06, 'epoch': 0.69}
{'loss': 0.0923, 'grad_norm': 1.2073510885238647, 'learning_rate': 2.2874549403182224e-06, 'epoch': 0.7}
{'loss': 0.0931, 'grad_norm': 1.1810450553894043, 'learning_rate': 2.2290488626356836e-06, 'epoch': 0.7}
{'loss': 0.0941, 'grad_norm': 1.2305915355682373, 'learning_rate': 2.171183467860136e-06, 'epoch': 0.7}
{'loss': 0.089, 'grad_norm': 1.2375096082687378, 'learning_rate': 2.113870046999e-06, 'epoch': 0.71}
{'loss': 0.0912, 'grad_norm': 1.248559594154358, 'learning_rate': 2.0571197833555756e-06, 'epoch': 0.71}
{'loss': 0.0888, 'grad_norm': 1.12991464138031, 'learning_rate': 2.000943750346896e-06, 'epoch': 0.72}
