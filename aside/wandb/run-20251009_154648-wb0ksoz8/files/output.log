[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                                                                              | 53/266 [11:38<46:06, 12.99s/it]
{'loss': 0.6916, 'grad_norm': 2.865802049636841, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': 0.0004138946533203125, 'rewards/rejected': -0.000530242919921875, 'rewards/accuracies': 0.203125, 'rewards/margins': 0.000946044921875, 'logps/chosen': -91.5, 'logps/rejected': -91.0, 'logits/chosen': nan, 'logits/rejected': nan, 'epoch': 0.04}
{'loss': 0.6878, 'grad_norm': 2.999232292175293, 'learning_rate': 7.037037037037037e-07, 'rewards/chosen': 0.007232666015625, 'rewards/rejected': -0.0024261474609375, 'rewards/accuracies': 0.43437498807907104, 'rewards/margins': 0.0096435546875, 'logps/chosen': -94.0, 'logps/rejected': -89.5, 'logits/chosen': -3.609375, 'logits/rejected': -3.671875, 'epoch': 0.08}
{'loss': 0.6645, 'grad_norm': 2.8604018688201904, 'learning_rate': 9.99827225784264e-07, 'rewards/chosen': 0.03271484375, 'rewards/rejected': -0.01373291015625, 'rewards/accuracies': 0.47187501192092896, 'rewards/margins': 0.04638671875, 'logps/chosen': -80.5, 'logps/rejected': -89.5, 'logits/chosen': -3.59375, 'logits/rejected': -3.484375, 'epoch': 0.11}
{'loss': 0.6111, 'grad_norm': 3.1913235187530518, 'learning_rate': 9.937926563848346e-07, 'rewards/chosen': 0.09912109375, 'rewards/rejected': -0.08935546875, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.1884765625, 'logps/chosen': -84.0, 'logps/rejected': -100.5, 'logits/chosen': -3.734375, 'logits/rejected': -3.796875, 'epoch': 0.15}
{'loss': 0.5376, 'grad_norm': 3.9282824993133545, 'learning_rate': 9.792384095234312e-07, 'rewards/chosen': 0.12109375, 'rewards/rejected': -0.275390625, 'rewards/accuracies': 0.528124988079071, 'rewards/margins': 0.396484375, 'logps/chosen': -75.5, 'logps/rejected': -112.5, 'logits/chosen': -4.90625, 'logits/rejected': -4.34375, 'epoch': 0.19}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                                                                              | 53/266 [12:16<46:06, 12.99s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-53                                                                          
{'eval_loss': 0.463992178440094, 'eval_runtime': 37.7507, 'eval_samples_per_second': 26.49, 'eval_steps_per_second': 0.848, 'eval_rewards/chosen': 0.169921875, 'eval_rewards/rejected': -0.64453125, 'eval_rewards/accuracies': 0.50390625, 'eval_rewards/margins': 0.8125, 'eval_logps/chosen': -70.0, 'eval_logps/rejected': -158.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.2}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-53/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-53/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-53/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-53/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-53/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-53/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                              | 106/266 [24:47<34:09, 12.81s/it]
{'loss': 0.4383, 'grad_norm': 2.6636300086975098, 'learning_rate': 9.564155976606338e-07, 'rewards/chosen': 0.1513671875, 'rewards/rejected': -0.734375, 'rewards/accuracies': 0.528124988079071, 'rewards/margins': 0.8828125, 'logps/chosen': -79.0, 'logps/rejected': -160.0, 'logits/chosen': -5.78125, 'logits/rejected': -5.40625, 'epoch': 0.23}
{'loss': 0.3412, 'grad_norm': 1.7429800033569336, 'learning_rate': 9.257179953763845e-07, 'rewards/chosen': 0.11328125, 'rewards/rejected': -1.9453125, 'rewards/accuracies': 0.59375, 'rewards/margins': 2.0625, 'logps/chosen': -85.0, 'logps/rejected': -294.0, 'logits/chosen': -5.75, 'logits/rejected': -5.6875, 'epoch': 0.26}
{'loss': 0.3136, 'grad_norm': 1.6251695156097412, 'learning_rate': 8.876752453596461e-07, 'rewards/chosen': 0.181640625, 'rewards/rejected': -2.671875, 'rewards/accuracies': 0.5718749761581421, 'rewards/margins': 2.859375, 'logps/chosen': -88.0, 'logps/rejected': -360.0, 'logits/chosen': -5.9375, 'logits/rejected': -5.6875, 'epoch': 0.3}
{'loss': 0.3248, 'grad_norm': 1.1673264503479004, 'learning_rate': 8.429437201905252e-07, 'rewards/chosen': 0.2158203125, 'rewards/rejected': -3.09375, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 3.3125, 'logps/chosen': -75.0, 'logps/rejected': -396.0, 'logits/chosen': -5.875, 'logits/rejected': -5.59375, 'epoch': 0.34}
{'loss': 0.2925, 'grad_norm': 0.33664241433143616, 'learning_rate': 7.92295197581581e-07, 'rewards/chosen': 0.24609375, 'rewards/rejected': -3.8125, 'rewards/accuracies': 0.590624988079071, 'rewards/margins': 4.0625, 'logps/chosen': -74.5, 'logps/rejected': -472.0, 'logits/chosen': -5.875, 'logits/rejected': -5.6875, 'epoch': 0.38}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                              | 106/266 [25:25<34:09, 12.81s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-106                                                                         
{'eval_loss': 0.34649237990379333, 'eval_runtime': 37.7401, 'eval_samples_per_second': 26.497, 'eval_steps_per_second': 0.848, 'eval_rewards/chosen': 0.181640625, 'eval_rewards/rejected': -3.671875, 'eval_rewards/accuracies': 0.51953125, 'eval_rewards/margins': 3.84375, 'eval_logps/chosen': -69.0, 'eval_logps/rejected': -460.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.4}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-106/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-106/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-106/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-106/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-106/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-106/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-53] due to args.save_total_limit
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 159/266 [38:15<23:04, 12.94s/it]
{'loss': 0.3128, 'grad_norm': 0.4788135886192322, 'learning_rate': 7.366035444706346e-07, 'rewards/chosen': 0.1982421875, 'rewards/rejected': -3.828125, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 4.03125, 'logps/chosen': -68.5, 'logps/rejected': -472.0, 'logits/chosen': -5.9375, 'logits/rejected': -5.5, 'epoch': 0.41}
{'loss': 0.3222, 'grad_norm': 1.2570090293884277, 'learning_rate': 6.768296397117847e-07, 'rewards/chosen': 0.1962890625, 'rewards/rejected': -3.671875, 'rewards/accuracies': 0.528124988079071, 'rewards/margins': 3.875, 'logps/chosen': -70.5, 'logps/rejected': -450.0, 'logits/chosen': -6.0625, 'logits/rejected': -5.34375, 'epoch': 0.45}
{'loss': 0.3331, 'grad_norm': 3.4885451793670654, 'learning_rate': 6.140047955017671e-07, 'rewards/chosen': 0.2099609375, 'rewards/rejected': -3.78125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 4.0, 'logps/chosen': -68.0, 'logps/rejected': -462.0, 'logits/chosen': -5.96875, 'logits/rejected': -5.84375, 'epoch': 0.49}
{'loss': 0.3063, 'grad_norm': 0.3734888732433319, 'learning_rate': 5.492129635809473e-07, 'rewards/chosen': 0.259765625, 'rewards/rejected': -4.5, 'rewards/accuracies': 0.5843750238418579, 'rewards/margins': 4.75, 'logps/chosen': -74.0, 'logps/rejected': -544.0, 'logits/chosen': -6.1875, 'logits/rejected': -5.8125, 'epoch': 0.53}
{'loss': 0.3141, 'grad_norm': 0.5374425649642944, 'learning_rate': 4.835720332151906e-07, 'rewards/chosen': 0.1904296875, 'rewards/rejected': -4.4375, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 4.625, 'logps/chosen': -68.0, 'logps/rejected': -536.0, 'logits/chosen': -6.09375, 'logits/rejected': -5.8125, 'epoch': 0.56}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 159/266 [38:53<23:04, 12.94s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-159                                                                         
{'eval_loss': 0.34195077419281006, 'eval_runtime': 37.7756, 'eval_samples_per_second': 26.472, 'eval_steps_per_second': 0.847, 'eval_rewards/chosen': 0.181640625, 'eval_rewards/rejected': -4.1875, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 4.375, 'eval_logps/chosen': -69.0, 'eval_logps/rejected': -512.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.6}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-159/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-159/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-159/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-159/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-159/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-159/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-106] due to args.save_total_limit
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 212/266 [51:38<11:39, 12.96s/it]          
{'loss': 0.3099, 'grad_norm': 1.0032602548599243, 'learning_rate': 4.1821454363485866e-07, 'rewards/chosen': 0.126953125, 'rewards/rejected': -4.125, 'rewards/accuracies': 0.528124988079071, 'rewards/margins': 4.25, 'logps/chosen': -79.5, 'logps/rejected': -498.0, 'logits/chosen': -6.125, 'logits/rejected': -5.78125, 'epoch': 0.6}
{'loss': 0.3003, 'grad_norm': 0.15653246641159058, 'learning_rate': 3.5426814370987443e-07, 'rewards/chosen': 0.208984375, 'rewards/rejected': -4.59375, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 4.78125, 'logps/chosen': -70.5, 'logps/rejected': -552.0, 'logits/chosen': -6.0625, 'logits/rejected': -5.59375, 'epoch': 0.64}
{'loss': 0.3159, 'grad_norm': 0.7838612794876099, 'learning_rate': 2.928361360008793e-07, 'rewards/chosen': 0.1826171875, 'rewards/rejected': -3.875, 'rewards/accuracies': 0.5406249761581421, 'rewards/margins': 4.0625, 'logps/chosen': -71.5, 'logps/rejected': -472.0, 'logits/chosen': nan, 'logits/rejected': nan, 'epoch': 0.68}
{'loss': 0.3025, 'grad_norm': 2.9303202629089355, 'learning_rate': 2.3497844087071118e-07, 'rewards/chosen': 0.1982421875, 'rewards/rejected': -4.5, 'rewards/accuracies': 0.596875011920929, 'rewards/margins': 4.6875, 'logps/chosen': -84.5, 'logps/rejected': -544.0, 'logits/chosen': -6.09375, 'logits/rejected': -5.8125, 'epoch': 0.71}
{'loss': 0.3008, 'grad_norm': 0.6419119834899902, 'learning_rate': 1.8169330909290548e-07, 'rewards/chosen': 0.2109375, 'rewards/rejected': -4.34375, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 4.5625, 'logps/chosen': -74.5, 'logps/rejected': -528.0, 'logits/chosen': -6.09375, 'logits/rejected': -5.59375, 'epoch': 0.75}
{'loss': 0.2976, 'grad_norm': 1.581761360168457, 'learning_rate': 1.3390009847968504e-07, 'rewards/chosen': 0.2265625, 'rewards/rejected': -4.46875, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 4.6875, 'logps/chosen': -72.5, 'logps/rejected': -540.0, 'logits/chosen': -5.9375, 'logits/rejected': -5.875, 'epoch': 0.79}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 212/266 [52:15<11:39, 12.96s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-212                                                               
{'eval_loss': 0.3416282534599304, 'eval_runtime': 37.8127, 'eval_samples_per_second': 26.446, 'eval_steps_per_second': 0.846, 'eval_rewards/chosen': 0.20703125, 'eval_rewards/rejected': -4.1875, 'eval_rewards/accuracies': 0.51953125, 'eval_rewards/margins': 4.375, 'eval_logps/chosen': -66.0, 'eval_logps/rejected': -512.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.8}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-212/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-212/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-212/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-212/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-212/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-212/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-159] due to args.save_total_limit
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 265/266 [1:04:56<00:12, 12.53s/it]
{'loss': 0.2933, 'grad_norm': 0.178684800863266, 'learning_rate': 9.242341169379075e-08, 'rewards/chosen': 0.26953125, 'rewards/rejected': -4.34375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 4.59375, 'logps/chosen': -64.0, 'logps/rejected': -524.0, 'logits/chosen': -6.0, 'logits/rejected': -5.65625, 'epoch': 0.83}
{'loss': 0.3027, 'grad_norm': 0.07648484408855438, 'learning_rate': 5.797886892324694e-08, 'rewards/chosen': 0.28515625, 'rewards/rejected': -4.34375, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 4.625, 'logps/chosen': -66.0, 'logps/rejected': -524.0, 'logits/chosen': -5.96875, 'logits/rejected': -6.0, 'epoch': 0.86}
{'loss': 0.3127, 'grad_norm': 0.6391421556472778, 'learning_rate': 3.116076089096264e-08, 'rewards/chosen': 0.1865234375, 'rewards/rejected': -4.0625, 'rewards/accuracies': 0.5406249761581421, 'rewards/margins': 4.25, 'logps/chosen': -68.0, 'logps/rejected': -484.0, 'logits/chosen': -6.125, 'logits/rejected': -5.6875, 'epoch': 0.9}
{'loss': 0.3136, 'grad_norm': 6.441251277923584, 'learning_rate': 1.2431795228615371e-08, 'rewards/chosen': 0.2001953125, 'rewards/rejected': -4.25, 'rewards/accuracies': 0.5218750238418579, 'rewards/margins': 4.46875, 'logps/chosen': -67.5, 'logps/rejected': -510.0, 'logits/chosen': -6.28125, 'logits/rejected': -5.875, 'epoch': 0.94}
{'loss': 0.321, 'grad_norm': 0.12838831543922424, 'learning_rate': 2.1151131262902577e-09, 'rewards/chosen': 0.271484375, 'rewards/rejected': -4.28125, 'rewards/accuracies': 0.5531250238418579, 'rewards/margins': 4.5625, 'logps/chosen': -61.5, 'logps/rejected': -516.0, 'logits/chosen': -6.28125, 'logits/rejected': -5.71875, 'epoch': 0.98}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 265/266 [1:05:33<00:12, 12.53s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265                                                               
{'eval_loss': 0.341058611869812, 'eval_runtime': 37.8108, 'eval_samples_per_second': 26.447, 'eval_steps_per_second': 0.846, 'eval_rewards/chosen': 0.20703125, 'eval_rewards/rejected': -4.21875, 'eval_rewards/accuracies': 0.51953125, 'eval_rewards/margins': 4.4375, 'eval_logps/chosen': -66.0, 'eval_logps/rejected': -516.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 1.0}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-212] due to args.save_total_limit
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:07:12<00:00, 49.55s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-266
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-266/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-266/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-266/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-266/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-266/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-266/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once


Training completed. Do not forget to share your model on huggingface.co/models =)


/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Loading best model from /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265 (score: 0.341058611869812).
Attempting to resume from /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-265
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:08:33<00:00, 49.55s/it]Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/checkpoint-266] due to args.save_total_limit
{'train_runtime': 4115.7916, 'train_samples_per_second': 8.272, 'train_steps_per_second': 0.065, 'train_loss': 0.37759350744405185, 'epoch': 1.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:08:45<00:00, 15.51s/it]
Custom impl., saving last checkpoint
 stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/special_tokens_map.json
Processing zero checkpoint '/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01/global_step265'
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1738.93it/s]
Detected checkpoint of type zero stage ZeroStageEnum.weights, world_size: 4
Parsing checkpoint created by deepspeed==0.17.6
Gathering sharded weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 399/399 [00:00<00:00, 1040750.81it/s]
Reconstructed Trainable fp32 state dict with 399 params 8188564480 elements
Saving checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [01:27<00:00, 12.51s/it]
Saved merged FP32 checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_lr1e-6_b0.01
