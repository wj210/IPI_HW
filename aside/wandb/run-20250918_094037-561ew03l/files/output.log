  4%|▍         | 10/240 [02:53<1:06:51, 17.44s/it]2025-09-18 09:43:33,329 - INFO - Step 10: Train Loss = 0.5776
Prompt : <|im_start|>system
# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{"name": "LogEntryManager.processLogEntries", "description": "Processes and stores log entries into the database with optional timestamp formatting.", "parameters": {"type": "dict", "properties": {"logEntries": {"description": "List of log entries to be processed.", "type": "array", "items": {"type": "dict", "properties": {"entryID": {"description": "Unique identifier for the log entry.", "type": "string"}, "entryMessage": {"description": "The message content of the log entry.", "type": "string"}, "entryTimestamp": {"description": "Timestamp of the log entry. Format must match '%Y-%m-%d %H:%M:%S'.", "type": "string", "pattern": "^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$"}}, "required": ["entryID", "entryMessage", "entryTimestamp"]}}, "databaseTable": {"description": "The database table where log entries will be stored.", "type": "string"}}, "required": ["logEntries", "databaseTable"]}, "required": null}
{"name": "DatabaseLogger.initializeConnection", "description": "Establishes a secure connection to the specified database for logging purposes, with configurable timeout and retry options.", "parameters": {"type": "dict", "properties": {"connectionDetails": {"description": "Details of the database connection.", "type": "dict", "properties": {"databaseURL": {"description": "The URL of the database to connect to.", "type": "string"}, "username": {"description": "The username for database authentication.", "type": "string"}, "password": {"description": "The password for database authentication.", "type": "string"}}, "required": ["databaseURL", "username", "password"]}, "timeout": {"description": "Connection timeout in seconds.", "type": "int"}, "retryOptions": {"description": "Options for connection retry.", "type": "dict", "properties": {"maxRetries": {"description": "Maximum number of retry attempts.", "type": "int"}, "retryDelay": {"description": "Delay between retries in seconds.", "type": "int"}}, "required": ["maxRetries", "retryDelay"]}}, "required": ["connectionDetails"]}, "required": null}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call><|im_end|>
<|im_start|>user
I need to process a batch of log entries into the 'app_logs' table. The entries are as follows: [{"entryID": "001", "entryMessage": "System startup", "entryTimestamp": "2023-09-01 12:00:00"}, {"entryID": "002", "entryMessage": "User login successful", "entryTimestamp": "2023-09-01 12:30:00"}]. Can you help with this?<|im_end|>
<|im_start|>assistant
<think>

</think>

<tool_call>
{"name": "LogEntryManager.processLogEntries", "arguments": {"logEntries": [{"entryID": "001", "entryMessage": "System startup", "entryTimestamp": "2023-09-01 12:00:00"}, {"entryID": "002", "entryMessage": "User login successful", "entryTimestamp": "2023-09-01 12:30:00"}], "databaseTable": "app_logs"}}
</tool_call><|im_end|>

{'loss': 0.5776, 'grad_norm': 5.360738277435303, 'learning_rate': 9e-06, 'epoch': 0.13}
  8%|▊         | 20/240 [05:44<1:03:39, 17.36s/it]2025-09-18 09:46:24,770 - INFO - Step 20: Train Loss = 0.3146
[2025-09-18 09:44:23,539] [WARNING] [stage3.py:2150:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3146, 'grad_norm': 0.7250161170959473, 'learning_rate': 9.962266933456008e-06, 'epoch': 0.25}
 12%|█▎        | 30/240 [08:28<57:02, 16.30s/it]2025-09-18 09:49:08,177 - INFO - Step 30: Train Loss = 0.2447
{'loss': 0.2447, 'grad_norm': 0.5483232140541077, 'learning_rate': 9.832562643088724e-06, 'epoch': 0.38}
 17%|█▋        | 40/240 [11:16<56:48, 17.04s/it]2025-09-18 09:51:56,975 - INFO - Step 40: Train Loss = 0.2133
{'loss': 0.2133, 'grad_norm': 0.5345306396484375, 'learning_rate': 9.61283685424036e-06, 'epoch': 0.5}
 21%|██        | 50/240 [14:05<53:11, 16.80s/it]2025-09-18 09:54:45,676 - INFO - Step 50: Train Loss = 0.2309
{'loss': 0.2309, 'grad_norm': 0.5712360739707947, 'learning_rate': 9.307182642620001e-06, 'epoch': 0.63}
 25%|██▌       | 60/240 [16:58<51:02, 17.01s/it]2025-09-18 09:57:38,773 - INFO - Step 60: Train Loss = 0.2807
{'loss': 0.2807, 'grad_norm': 0.6811343431472778, 'learning_rate': 8.921293767870157e-06, 'epoch': 0.76}
 29%|██▉       | 70/240 [19:49<49:25, 17.45s/it]2025-09-18 10:00:29,850 - INFO - Step 70: Train Loss = 0.2447
[2025-09-18 09:58:30,588] [WARNING] [stage3.py:2150:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.2447, 'grad_norm': 0.6300989389419556, 'learning_rate': 8.462358609597629e-06, 'epoch': 0.88}
 33%|███▎      | 80/240 [22:22<34:55, 13.10s/it]2025-09-18 10:03:02,801 - INFO - Step 80: Train Loss = 0.2447
{'loss': 0.2447, 'grad_norm': 0.49512484669685364, 'learning_rate': 7.938926261462366e-06, 'epoch': 1.0}

***** Running Evaluation *****
  Num examples = 469
  Batch size = 8
Prompt : <|im_start|>system
# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{"name": "Get Greet", "description": "Generates a personalized greeting message based on the provided name and cringe level.", "parameters": {"type": "dict", "properties": {"name": {"description": "The name of the person to be greeted.", "type": "string"}, "cringeLevel": {"description": "The level of cringe to include in the greeting message.", "type": "int"}}, "required": ["name", "cringeLevel"]}, "required": null}
{"name": "Twitter Auto Complete", "description": "Auto complete search queries on Twitter", "parameters": {"type": "dict", "properties": {"q": {"description": "Search query", "type": "string"}}, "required": ["q"]}, "required": null}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call><|im_end|>
<|im_start|>user
Can you create personalized greetings for four of my friends? Their names are Alex, Jamie, Taylor, and Jordan. I want different levels of cringe for each: 1 for Alex, 2 for Jamie, 3 for Taylor, and 4 for Jordan.<|im_end|>
<|im_start|>assistant
<think>

</think>

<tool_call>
{"name": "Get Greet", "arguments": {"name": "Alex", "cringeLevel": 1}}
</tool_call>
<tool_call>
{"name": "Get Greet", "arguments": {"name": "Jamie", "cringeLevel": 2}}
</tool_call>
<tool_call>
{"name": "Get Greet", "arguments": {"name": "Taylor", "cringeLevel": 3}}
</tool_call>
<tool_call>
{"name": "Get Greet", "arguments": {"name": "Jordan", "cringeLevel": 4}}
</tool_call><|im_end|>
 33%|███▎      | 80/240 [22:37<34:55, 13.10s/it2025-09-18 10:03:17,784 - INFO - Step 80: Eval Loss = 0.2121
100%|██████████| 15/15 [00:14<00:00,  1.08s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights

{'eval_loss': 0.21210835874080658, 'eval_runtime': 14.9758, 'eval_samples_per_second': 31.317, 'eval_steps_per_second': 1.002, 'epoch': 1.0}
Saving model checkpoint to /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80
Configuration saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/config.json
Configuration saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/generation_config.json
Model weights saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/model.safetensors
chat template saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/chat_template.jinja
tokenizer config file saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/tokenizer_config.json
Special tokens file saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/special_tokens_map.json
[2025-09-18 10:03:18,084] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step79 is about to be saved!
[2025-09-18 10:03:18,092] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-09-18 10:03:18,092] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-09-18 10:03:18,107] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-09-18 10:03:18,110] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-09-18 10:04:59,391] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-09-18 10:04:59,400] [INFO] [engine.py:3710:_save_zero_checkpoint] zero checkpoint saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-09-18 10:04:59,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step79 is ready now!
[2025-09-18 10:04:59,425] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step79 is about to be saved!
[2025-09-18 10:04:59,431] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-09-18 10:04:59,431] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-09-18 10:04:59,446] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-09-18 10:04:59,448] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-09-18 10:06:39,814] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-09-18 10:06:39,856] [INFO] [engine.py:3710:_save_zero_checkpoint] zero checkpoint saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80/global_step79/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-09-18 10:06:40,350] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step79 is ready now!
Deleting older checkpoint [/dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-80] due to args.save_total_limit
 38%|███▊      | 90/240 [28:47<47:26, 18.98s/it]2025-09-18 10:09:27,389 - INFO - Step 90: Train Loss = 0.1746
{'loss': 0.1746, 'grad_norm': 0.6179137825965881, 'learning_rate': 7.360747277738094e-06, 'epoch': 1.13}
 42%|████▏     | 100/240 [31:27<38:00, 16.29s/it]2025-09-18 10:12:07,761 - INFO - Step 100: Train Loss = 0.1692
{'loss': 0.1692, 'grad_norm': 0.6092642545700073, 'learning_rate': 6.738592038934946e-06, 'epoch': 1.25}
 46%|████▌     | 110/240 [34:12<35:31, 16.40s/it]2025-09-18 10:14:52,354 - INFO - Step 110: Train Loss = 0.1592
{'loss': 0.1592, 'grad_norm': 0.5303633809089661, 'learning_rate': 6.084050119988905e-06, 'epoch': 1.38}
 50%|█████     | 120/240 [36:55<32:59, 16.50s/it]2025-09-18 10:17:35,432 - INFO - Step 120: Train Loss = 0.1578
{'loss': 0.1578, 'grad_norm': 0.5319079160690308, 'learning_rate': 5.409314398409067e-06, 'epoch': 1.5}
 54%|█████▍    | 130/240 [39:48<31:09, 16.99s/it]2025-09-18 10:20:28,241 - INFO - Step 130: Train Loss = 0.1519
{'loss': 0.1519, 'grad_norm': 0.672943115234375, 'learning_rate': 4.7269539240394505e-06, 'epoch': 1.63}
 58%|█████▊    | 140/240 [42:41<28:18, 16.99s/it]2025-09-18 10:23:21,274 - INFO - Step 140: Train Loss = 0.1621
{'loss': 0.1621, 'grad_norm': 0.5021870136260986, 'learning_rate': 4.0496797814419655e-06, 'epoch': 1.76}
 62%|██████▎   | 150/240 [45:30<24:54, 16.61s/it]2025-09-18 10:26:10,639 - INFO - Step 150: Train Loss = 0.1925
{'loss': 0.1925, 'grad_norm': 0.6460372805595398, 'learning_rate': 3.39010830644131e-06, 'epoch': 1.88}
 67%|██████▋   | 160/240 [48:04<17:02, 12.78s/it]2025-09-18 10:28:45,027 - INFO - Step 160: Train Loss = 0.1462
{'loss': 0.1462, 'grad_norm': 0.5710732340812683, 'learning_rate': 2.760526067659591e-06, 'epoch': 2.0}

***** Running Evaluation *****
  Num examples = 469
  Batch size = 8
 67%|██████▋   | 160/240 [48:19<17:02, 12.78s/i2025-09-18 10:28:59,702 - INFO - Step 160: Eval Loss = 0.2218
100%|██████████| 15/15 [00:13<00:00,  1.04s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
{'eval_loss': 0.22183415293693542, 'eval_runtime': 14.6589, 'eval_samples_per_second': 31.994, 'eval_steps_per_second': 1.023, 'epoch': 2.0}
Saving model checkpoint to /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160
Configuration saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/config.json
Configuration saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/generation_config.json
Model weights saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/model.safetensors
chat template saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/chat_template.jinja
tokenizer config file saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/tokenizer_config.json
Special tokens file saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/special_tokens_map.json
[2025-09-18 10:28:59,934] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step158 is about to be saved!
[2025-09-18 10:28:59,941] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-09-18 10:28:59,941] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-09-18 10:28:59,956] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-09-18 10:29:00,300] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-09-18 10:30:40,931] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-09-18 10:30:40,980] [INFO] [engine.py:3710:_save_zero_checkpoint] zero checkpoint saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-09-18 10:30:42,096] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step158 is ready now!
[2025-09-18 10:30:42,111] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step158 is about to be saved!
[2025-09-18 10:30:42,118] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-09-18 10:30:42,118] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-09-18 10:30:42,132] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-09-18 10:30:42,134] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-09-18 10:32:23,451] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-09-18 10:32:23,460] [INFO] [engine.py:3710:_save_zero_checkpoint] zero checkpoint saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160/global_step158/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-09-18 10:32:23,469] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step158 is ready now!
 71%|███████   | 170/240 [54:31<22:36, 19.37s/it]2025-09-18 10:35:11,297 - INFO - Step 170: Train Loss = 0.1138
{'loss': 0.1138, 'grad_norm': 0.5599059462547302, 'learning_rate': 2.172660990989971e-06, 'epoch': 2.13}
 75%|███████▌  | 180/240 [57:19<16:41, 16.70s/it]2025-09-18 10:37:59,502 - INFO - Step 180: Train Loss = 0.1151
{'loss': 0.1151, 'grad_norm': 0.6716145277023315, 'learning_rate': 1.6374638905273643e-06, 'epoch': 2.25}
 79%|███████▉  | 190/240 [1:00:10<14:38, 17.57s/it]2025-09-18 10:40:50,903 - INFO - Step 190: Train Loss = 0.1003
{'loss': 0.1003, 'grad_norm': 0.6043083667755127, 'learning_rate': 1.1649044756215872e-06, 'epoch': 2.38}
 83%|████████▎ | 200/240 [1:02:59<11:28, 17.20s/it]2025-09-18 10:43:39,143 - INFO - Step 200: Train Loss = 0.0935
{'loss': 0.0935, 'grad_norm': 0.7981964349746704, 'learning_rate': 7.637856340555822e-07, 'epoch': 2.5}
 88%|████████▊ | 210/240 [1:05:45<08:18, 16.62s/it]2025-09-18 10:46:25,225 - INFO - Step 210: Train Loss = 0.0958
{'loss': 0.0958, 'grad_norm': 0.48884499073028564, 'learning_rate': 4.4157945090173294e-07, 'epoch': 2.63}
 92%|█████████▏| 220/240 [1:08:32<05:30, 16.53s/it]2025-09-18 10:49:12,739 - INFO - Step 220: Train Loss = 0.0961
{'loss': 0.0961, 'grad_norm': 0.7001888155937195, 'learning_rate': 2.0428801771468388e-07, 'epoch': 2.76}
 96%|█████████▌| 230/240 [1:11:17<02:46, 16.66s/it]2025-09-18 10:51:57,267 - INFO - Step 230: Train Loss = 0.0951
{'loss': 0.0951, 'grad_norm': 0.671500563621521, 'learning_rate': 5.633162492207633e-08, 'epoch': 2.88}
100%|██████████| 240/240 [1:13:51<00:00, 12.68s/it]2025-09-18 10:54:31,925 - INFO - Step 240: Train Loss = 0.0983
{'loss': 0.0983, 'grad_norm': 0.6409708857536316, 'learning_rate': 4.664201773896259e-10, 'epoch': 3.0}

***** Running Evaluation *****
  Num examples = 469
  Batch size = 8
100%|██████████| 240/240 [1:14:06<00:00, 12.68s2025-09-18 10:54:46,571 - INFO - Step 240: Eval Loss = 0.2455
100%|██████████| 15/15 [00:13<00:00,  1.04s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
{'eval_loss': 0.24547380208969116, 'eval_runtime': 14.6363, 'eval_samples_per_second': 32.044, 'eval_steps_per_second': 1.025, 'epoch': 3.0}
Saving model checkpoint to /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240
Configuration saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/config.json
Configuration saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/generation_config.json
Model weights saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/model.safetensors
chat template saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/chat_template.jinja
tokenizer config file saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/tokenizer_config.json
Special tokens file saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/special_tokens_map.json
[2025-09-18 10:54:46,813] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step237 is about to be saved!
[2025-09-18 10:54:46,820] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-09-18 10:54:46,820] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-09-18 10:54:46,836] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-09-18 10:54:46,839] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-09-18 10:56:28,453] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-09-18 10:56:28,486] [INFO] [engine.py:3710:_save_zero_checkpoint] zero checkpoint saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-09-18 10:56:29,352] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step237 is ready now!
[2025-09-18 10:56:29,366] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step237 is about to be saved!
[2025-09-18 10:56:29,373] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-09-18 10:56:29,373] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-09-18 10:56:29,387] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-09-18 10:56:29,389] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-09-18 10:58:10,194] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-09-18 10:58:10,203] [INFO] [engine.py:3710:_save_zero_checkpoint] zero checkpoint saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-240/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-09-18 10:58:10,212] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step237 is ready now!
Deleting older checkpoint [/dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/checkpoint-160] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|██████████| 240/240 [1:17:32<00:00, 19.39s/it]
{'train_runtime': 4656.3011, 'train_samples_per_second': 6.534, 'train_steps_per_second': 0.052, 'train_loss': 0.18636585002144176, 'epoch': 3.0}
Custom impl., saving last checkpoint
 stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70
Configuration saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/config.json
Configuration saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/generation_config.json
Model weights saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/model.safetensors
chat template saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/chat_template.jinja
tokenizer config file saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/tokenizer_config.json
Special tokens file saved in /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/special_tokens_map.json
[2025-09-18 10:58:13,253] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step237 is about to be saved!
[2025-09-18 10:58:13,261] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-09-18 10:58:13,261] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-09-18 10:58:13,277] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/global_step237/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-09-18 10:58:13,280] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-09-18 10:59:53,405] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-09-18 10:59:53,442] [INFO] [engine.py:3710:_save_zero_checkpoint] zero checkpoint saved /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/global_step237/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-09-18 10:59:54,084] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step237 is ready now!
Processing zero checkpoint '/dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70/global_step237'
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]
Detected checkpoint of type zero stage 3, world_size: 4
Parsing checkpoint created by deepspeed==0.17.0
Gathering sharded weights: 100%|██████████| 399/399 [00:00<00:00, 840968.49it/s]
Reconstructed Trainable fp32 state dict with 399 params 8190735360 elements
Saving checkpoint shards: 100%|██████████| 7/7 [02:08<00:00, 18.42s/it]
Saved merged FP32 checkpoint to /dataset/common/huggingface/model/qwen3_8b_InstructToolace_SFTv70
