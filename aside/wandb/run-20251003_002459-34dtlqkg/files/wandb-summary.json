{"train_samples_per_second":3.039,"train/global_step":292,"train/rewards/chosen":4.75,"train/grad_norm":3.8785574436187744,"eval/rewards/chosen":4.65625,"eval/logps/chosen":-138,"train/logps/rejected":-248,"train/rewards/margins":12.875,"eval/logits/rejected":-3.84375,"eval/loss":0.004110041540116072,"train/loss":0.0064,"train/rewards/rejected":-8.125,"eval/rewards/rejected":-8.1875,"train_steps_per_second":0.048,"_step":39,"eval/steps_per_second":0.441,"_wandb":{"runtime":6385},"eval/logps/rejected":-306,"train_runtime":6138.7155,"eval/logits/chosen":-4.75,"train/logps/chosen":-125,"_runtime":6385,"train/epoch":1,"total_flos":0,"eval/rewards/margins":12.875,"train_loss":0.10558700345277991,"train/rewards/accuracies":1,"eval/runtime":36.2545,"eval/samples_per_second":13.791,"train/learning_rate":1.6173456793908135e-10,"train/logits/rejected":-4.4375,"_timestamp":1.7594284376756792e+09,"eval/rewards/accuracies":0.9921875,"train/logits/chosen":-5}