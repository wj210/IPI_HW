{"train_steps_per_second":0.064,"train/rewards/chosen":1.984375,"eval/steps_per_second":0.841,"eval/rewards/accuracies":0.5234375,"train/loss":0.3129,"train/grad_norm":4.59281587600708,"eval/logps/chosen":-69.5,"eval/samples_per_second":26.269,"train/logits/chosen":-5.375,"train/epoch":1,"eval/rewards/rejected":-6.71875,"train/global_step":266,"train/learning_rate":2.1151131262902577e-09,"train/logps/chosen":-80.5,"eval/rewards/chosen":1.7265625,"_wandb":{"runtime":4282},"eval/runtime":38.0679,"eval/rewards/margins":8.4375,"eval/loss":0.33440396189689636,"eval/logits/rejected":NaN,"_timestamp":1.759988823072871e+09,"_step":31,"train/logps/rejected":-163,"train/rewards/rejected":-7.28125,"train_samples_per_second":8.18,"train/rewards/accuracies":0.565625011920929,"_runtime":4282,"train_runtime":4161.977,"train/logits/rejected":-4.75,"train/rewards/margins":9.25,"eval/logps/rejected":-161,"total_flos":0,"train_loss":0.34271142895060375,"eval/logits/chosen":NaN}