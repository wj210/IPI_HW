[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                                                                                     | 53/266 [12:07<46:55, 13.22s/it]
{'loss': 0.6905, 'grad_norm': 28.882373809814453, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': -0.000396728515625, 'rewards/rejected': 0.00156402587890625, 'rewards/accuracies': 0.19062499701976776, 'rewards/margins': -0.001953125, 'logps/chosen': -96.5, 'logps/rejected': -91.5, 'logits/chosen': nan, 'logits/rejected': nan, 'epoch': 0.04}
{'loss': 0.6462, 'grad_norm': 28.744247436523438, 'learning_rate': 7.037037037037037e-07, 'rewards/chosen': 0.058837890625, 'rewards/rejected': -0.052490234375, 'rewards/accuracies': 0.4156250059604645, 'rewards/margins': 0.111328125, 'logps/chosen': -94.5, 'logps/rejected': -91.0, 'logits/chosen': -3.78125, 'logits/rejected': -3.8125, 'epoch': 0.08}
{'loss': 0.5011, 'grad_norm': 10.909821510314941, 'learning_rate': 9.99827225784264e-07, 'rewards/chosen': 0.2734375, 'rewards/rejected': -0.283203125, 'rewards/accuracies': 0.484375, 'rewards/margins': 0.55859375, 'logps/chosen': -84.0, 'logps/rejected': -84.5, 'logits/chosen': -3.765625, 'logits/rejected': -3.78125, 'epoch': 0.11}
{'loss': 0.3849, 'grad_norm': 6.652237892150879, 'learning_rate': 9.937926563848346e-07, 'rewards/chosen': 0.7890625, 'rewards/rejected': -0.97265625, 'rewards/accuracies': 0.565625011920929, 'rewards/margins': 1.765625, 'logps/chosen': -88.5, 'logps/rejected': -110.0, 'logits/chosen': -3.84375, 'logits/rejected': -3.5, 'epoch': 0.15}
{'loss': 0.332, 'grad_norm': 3.37872576713562, 'learning_rate': 9.792384095234312e-07, 'rewards/chosen': 0.8671875, 'rewards/rejected': -1.96875, 'rewards/accuracies': 0.53125, 'rewards/margins': 2.84375, 'logps/chosen': -80.5, 'logps/rejected': -107.0, 'logits/chosen': -4.28125, 'logits/rejected': -4.0, 'epoch': 0.19}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                                                                                     | 53/266 [12:45<46:55, 13.22s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-53                                                                                                       
{'eval_loss': 0.35026562213897705, 'eval_runtime': 38.0425, 'eval_samples_per_second': 26.286, 'eval_steps_per_second': 0.841, 'eval_rewards/chosen': 0.62109375, 'eval_rewards/rejected': -2.75, 'eval_rewards/accuracies': 0.51171875, 'eval_rewards/margins': 3.375, 'eval_logps/chosen': -80.5, 'eval_logps/rejected': -121.5, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.2}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-53/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-53/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-53/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-53/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-53/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-53/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                            | 106/266 [25:30<34:33, 12.96s/it]
{'loss': 0.3269, 'grad_norm': 0.8518924117088318, 'learning_rate': 9.564155976606338e-07, 'rewards/chosen': 0.96875, 'rewards/rejected': -3.03125, 'rewards/accuracies': 0.5531250238418579, 'rewards/margins': 4.0, 'logps/chosen': -81.0, 'logps/rejected': -118.5, 'logits/chosen': -4.78125, 'logits/rejected': -4.375, 'epoch': 0.23}
{'loss': 0.2946, 'grad_norm': 2.2477612495422363, 'learning_rate': 9.257179953763845e-07, 'rewards/chosen': 1.5703125, 'rewards/rejected': -4.4375, 'rewards/accuracies': 0.59375, 'rewards/margins': 6.0, 'logps/chosen': -84.5, 'logps/rejected': -141.0, 'logits/chosen': -5.09375, 'logits/rejected': -4.6875, 'epoch': 0.26}
{'loss': 0.2949, 'grad_norm': 1.501542568206787, 'learning_rate': 8.876752453596461e-07, 'rewards/chosen': 1.796875, 'rewards/rejected': -4.8125, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 6.59375, 'logps/chosen': -67.5, 'logps/rejected': -137.0, 'logits/chosen': -5.40625, 'logits/rejected': -4.8125, 'epoch': 0.3}
{'loss': 0.3156, 'grad_norm': 1.5200889110565186, 'learning_rate': 8.429437201905252e-07, 'rewards/chosen': 1.8359375, 'rewards/rejected': -5.25, 'rewards/accuracies': 0.5687500238418579, 'rewards/margins': 7.09375, 'logps/chosen': -80.0, 'logps/rejected': -136.0, 'logits/chosen': -5.46875, 'logits/rejected': -4.84375, 'epoch': 0.34}
{'loss': 0.2871, 'grad_norm': 1.0149060487747192, 'learning_rate': 7.92295197581581e-07, 'rewards/chosen': 1.65625, 'rewards/rejected': -5.78125, 'rewards/accuracies': 0.6031249761581421, 'rewards/margins': 7.4375, 'logps/chosen': -81.0, 'logps/rejected': -148.0, 'logits/chosen': -5.28125, 'logits/rejected': -4.875, 'epoch': 0.38}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                            | 106/266 [26:08<34:33, 12.96s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-106                                                                                                      
{'eval_loss': 0.33751678466796875, 'eval_runtime': 37.9619, 'eval_samples_per_second': 26.342, 'eval_steps_per_second': 0.843, 'eval_rewards/chosen': 1.7421875, 'eval_rewards/rejected': -5.1875, 'eval_rewards/accuracies': 0.515625, 'eval_rewards/margins': 6.9375, 'eval_logps/chosen': -69.5, 'eval_logps/rejected': -146.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.4}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-106/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-106/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-106/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-106/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-106/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-106/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-53] due to args.save_total_limit
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                  | 159/266 [38:55<23:01, 12.91s/it]
{'loss': 0.3059, 'grad_norm': 1.1952779293060303, 'learning_rate': 7.366035444706346e-07, 'rewards/chosen': 1.7265625, 'rewards/rejected': -5.53125, 'rewards/accuracies': 0.5406249761581421, 'rewards/margins': 7.25, 'logps/chosen': -68.0, 'logps/rejected': -140.0, 'logits/chosen': -5.4375, 'logits/rejected': -5.0, 'epoch': 0.41}
{'loss': 0.3129, 'grad_norm': 0.32870596647262573, 'learning_rate': 6.768296397117847e-07, 'rewards/chosen': 1.9375, 'rewards/rejected': -5.25, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 7.21875, 'logps/chosen': -68.5, 'logps/rejected': -140.0, 'logits/chosen': -5.125, 'logits/rejected': -4.625, 'epoch': 0.45}
{'loss': 0.3255, 'grad_norm': 0.15092474222183228, 'learning_rate': 6.140047955017671e-07, 'rewards/chosen': 2.25, 'rewards/rejected': -5.34375, 'rewards/accuracies': 0.53125, 'rewards/margins': 7.59375, 'logps/chosen': -69.0, 'logps/rejected': -138.0, 'logits/chosen': -5.0625, 'logits/rejected': -4.59375, 'epoch': 0.49}
{'loss': 0.3027, 'grad_norm': 0.10742780566215515, 'learning_rate': 5.492129635809473e-07, 'rewards/chosen': 2.640625, 'rewards/rejected': -5.875, 'rewards/accuracies': 0.578125, 'rewards/margins': 8.5, 'logps/chosen': -73.5, 'logps/rejected': -153.0, 'logits/chosen': -5.25, 'logits/rejected': -4.65625, 'epoch': 0.53}
{'loss': 0.3116, 'grad_norm': 0.48932012915611267, 'learning_rate': 4.835720332151906e-07, 'rewards/chosen': 2.421875, 'rewards/rejected': -6.40625, 'rewards/accuracies': 0.559374988079071, 'rewards/margins': 8.8125, 'logps/chosen': -67.5, 'logps/rejected': -159.0, 'logits/chosen': -5.4375, 'logits/rejected': -4.75, 'epoch': 0.56}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                  | 159/266 [39:33<23:01, 12.91s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-159                                                                                                      
{'eval_loss': 0.33506983518600464, 'eval_runtime': 37.9995, 'eval_samples_per_second': 26.316, 'eval_steps_per_second': 0.842, 'eval_rewards/chosen': 1.96875, 'eval_rewards/rejected': -6.03125, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 8.0, 'eval_logps/chosen': -67.5, 'eval_logps/rejected': -154.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.6}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-159/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-159/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-159/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-159/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-159/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-159/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-106] due to args.save_total_limit
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 212/266 [52:19<11:37, 12.91s/it]
{'loss': 0.301, 'grad_norm': 0.18742574751377106, 'learning_rate': 4.1821454363485866e-07, 'rewards/chosen': 2.109375, 'rewards/rejected': -5.84375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 7.96875, 'logps/chosen': -67.0, 'logps/rejected': -144.0, 'logits/chosen': -5.40625, 'logits/rejected': -4.9375, 'epoch': 0.6}
{'loss': 0.2969, 'grad_norm': 0.29227548837661743, 'learning_rate': 3.5426814370987443e-07, 'rewards/chosen': 2.125, 'rewards/rejected': -6.875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 9.0, 'logps/chosen': -69.5, 'logps/rejected': -166.0, 'logits/chosen': -5.4375, 'logits/rejected': -4.78125, 'epoch': 0.64}
{'loss': 0.3101, 'grad_norm': 0.02352236956357956, 'learning_rate': 2.928361360008793e-07, 'rewards/chosen': 1.953125, 'rewards/rejected': -6.28125, 'rewards/accuracies': 0.53125, 'rewards/margins': 8.25, 'logps/chosen': -72.5, 'logps/rejected': -146.0, 'logits/chosen': nan, 'logits/rejected': nan, 'epoch': 0.68}
{'loss': 0.2948, 'grad_norm': 0.10723292082548141, 'learning_rate': 2.3497844087071118e-07, 'rewards/chosen': 1.9375, 'rewards/rejected': -7.75, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 9.6875, 'logps/chosen': -73.5, 'logps/rejected': -179.0, 'logits/chosen': -5.4375, 'logits/rejected': -4.875, 'epoch': 0.71}
{'loss': 0.2917, 'grad_norm': 0.6455886363983154, 'learning_rate': 1.8169330909290548e-07, 'rewards/chosen': 1.828125, 'rewards/rejected': -7.46875, 'rewards/accuracies': 0.578125, 'rewards/margins': 9.3125, 'logps/chosen': -72.0, 'logps/rejected': -168.0, 'logits/chosen': -5.625, 'logits/rejected': -5.09375, 'epoch': 0.75}
{'loss': 0.2941, 'grad_norm': 0.004533069208264351, 'learning_rate': 1.3390009847968504e-07, 'rewards/chosen': 1.7890625, 'rewards/rejected': -7.21875, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 9.0, 'logps/chosen': -78.0, 'logps/rejected': -157.0, 'logits/chosen': -5.4375, 'logits/rejected': -5.0625, 'epoch': 0.79}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 212/266 [52:57<11:37, 12.91s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212                                                                                                      
{'eval_loss': 0.33439886569976807, 'eval_runtime': 38.0043, 'eval_samples_per_second': 26.313, 'eval_steps_per_second': 0.842, 'eval_rewards/chosen': 1.6953125, 'eval_rewards/rejected': -6.6875, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 8.375, 'eval_logps/chosen': -70.0, 'eval_logps/rejected': -161.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 0.8}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-159] due to args.save_total_limit
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 265/266 [1:05:41<00:12, 12.89s/it]
{'loss': 0.2871, 'grad_norm': 0.008402957580983639, 'learning_rate': 9.242341169379075e-08, 'rewards/chosen': 1.671875, 'rewards/rejected': -7.65625, 'rewards/accuracies': 0.5687500238418579, 'rewards/margins': 9.3125, 'logps/chosen': -74.5, 'logps/rejected': -173.0, 'logits/chosen': -5.53125, 'logits/rejected': -5.0625, 'epoch': 0.83}
{'loss': 0.2993, 'grad_norm': 0.34580060839653015, 'learning_rate': 5.797886892324694e-08, 'rewards/chosen': 1.8671875, 'rewards/rejected': -7.40625, 'rewards/accuracies': 0.5718749761581421, 'rewards/margins': 9.25, 'logps/chosen': -76.0, 'logps/rejected': -171.0, 'logits/chosen': -5.3125, 'logits/rejected': -4.9375, 'epoch': 0.86}
{'loss': 0.3146, 'grad_norm': 1.659323811531067, 'learning_rate': 3.116076089096264e-08, 'rewards/chosen': 1.7265625, 'rewards/rejected': -6.8125, 'rewards/accuracies': 0.515625, 'rewards/margins': 8.5625, 'logps/chosen': -71.0, 'logps/rejected': -150.0, 'logits/chosen': -5.40625, 'logits/rejected': -4.96875, 'epoch': 0.9}
{'loss': 0.3083, 'grad_norm': 3.814692735671997, 'learning_rate': 1.2431795228615371e-08, 'rewards/chosen': 1.46875, 'rewards/rejected': -7.03125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 8.5, 'logps/chosen': -60.0, 'logps/rejected': -158.0, 'logits/chosen': -5.71875, 'logits/rejected': -5.0, 'epoch': 0.94}
{'loss': 0.3129, 'grad_norm': 4.59281587600708, 'learning_rate': 2.1151131262902577e-09, 'rewards/chosen': 1.984375, 'rewards/rejected': -7.28125, 'rewards/accuracies': 0.565625011920929, 'rewards/margins': 9.25, 'logps/chosen': -80.5, 'logps/rejected': -163.0, 'logits/chosen': -5.375, 'logits/rejected': -4.75, 'epoch': 0.98}
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 8
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 265/266 [1:06:19<00:12, 12.89s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-265                                                                                                      
{'eval_loss': 0.33440396189689636, 'eval_runtime': 38.0679, 'eval_samples_per_second': 26.269, 'eval_steps_per_second': 0.841, 'eval_rewards/chosen': 1.7265625, 'eval_rewards/rejected': -6.71875, 'eval_rewards/accuracies': 0.5234375, 'eval_rewards/margins': 8.4375, 'eval_logps/chosen': -69.5, 'eval_logps/rejected': -161.0, 'eval_logits/chosen': nan, 'eval_logits/rejected': nan, 'epoch': 1.0}
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-265/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-265/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-265/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-265/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-265/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-265/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:07:45<00:00, 46.18s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-266
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-266/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-266/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-266/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-266/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-266/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-266/special_tokens_map.json
/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-265] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


/home/wjyeo/anaconda3/envs/ipi_hw/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
Loading best model from /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212 (score: 0.33439886569976807).
Attempting to resume from /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-212
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:09:19<00:00, 46.18s/it]Deleting older checkpoint [/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/checkpoint-266] due to args.save_total_limit
{'train_runtime': 4161.977, 'train_samples_per_second': 8.18, 'train_steps_per_second': 0.064, 'train_loss': 0.34271142895060375, 'epoch': 1.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266/266 [1:09:29<00:00, 15.67s/it]
Custom impl., saving last checkpoint
 stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/config.json
Configuration saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/generation_config.json
Model weights saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/model.safetensors
chat template saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/chat_template.jinja
tokenizer config file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/tokenizer_config.json
Special tokens file saved in /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/special_tokens_map.json
Processing zero checkpoint '/mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1/global_step212'
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1679.74it/s]
Detected checkpoint of type zero stage ZeroStageEnum.weights, world_size: 4
Parsing checkpoint created by deepspeed==0.17.6
Gathering sharded weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 399/399 [00:00<00:00, 1008148.97it/s]
Reconstructed Trainable fp32 state dict with 399 params 8188564480 elements
Saving checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [01:21<00:00, 11.65s/it]
Saved merged FP32 checkpoint to /mnt/disk1/wjyeo/models/MetaSecAlign/Qwen3-8B_dpo_Vanilla_ToolAlpaca_MetaSecAlign_Vanilla_lr1e-6_b0.1
